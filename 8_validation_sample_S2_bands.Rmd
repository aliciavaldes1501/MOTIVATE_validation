---
title: "Script to validate points in ReSurvey database using RS data"
subtitle: "Validation done with a sample of points (last observations)"
author: "Alicia Vald√©s"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  pdf_document: default
  html_notebook: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE)
```

This R script is used to validate the points in the ReSurvey database using RS indicators (indices + phenology + canopy height).

# Load libraries

```{r}
library(tidyverse)
library(here)
library(gridExtra)
library(readxl)
library(scales)
library(sf)
library(rnaturalearth)
library(dtplyr)
library(lme4)
library(lmerTest)
library(car)
library(ggeffects)
library(party)
library(partykit)
library(strucchange)
library(ggparty)
library(caret)
library(moreparty)
library(randomForest)
library(pROC)
```

# Define printall function

```{r}
printall <- function(tibble) {
  print(tibble, width = Inf)
  }
```

# Load geom_flat_violin plot

```{r}
source("https://gist.githubusercontent.com/benmarwick/2a1bb0133ff568cbe28d/raw/fb53bd97121f7f9ce947837ef1a4c65a73bffb3f/geom_flat_violin.R")
```

# Read data

```{r}
data_validation<-read_tsv(here("data", "clean","final_RS_data_bands_S2.csv"))
```

No parsing issues!

# Some data managenemt

## Several EUNIS level 1 assigned

Number of rows where there is more than one EUNIS 1 assigned, and they are different among them. See what to do with these later! So far I take EUNISa_1.

```{r}
nrow(db_resurv_RS %>% 
       # Rows with more than one EUNIS 1 assigned
       filter(!is.na(EUNISb_1)) %>% 
       filter(EUNISa_1!=EUNISb_1 | EUNISb_1 != EUNISc_1 | EUNISa_1 != EUNISc_1))
```

See "confusions":

```{r}
db_resurv_RS %>% 
  # Rows with more than one EUNIS 1 assigned
  filter(!is.na(EUNISb_1)) %>% 
  filter(EUNISa_1!=EUNISb_1 | EUNISb_1 != EUNISc_1 | EUNISa_1 != EUNISc_1) %>%
  distinct(EUNISa_1, EUNISb_1, EUNISc_1, EUNISd_1)
```

Define "confusion" columns:

```{r}
db_resurv_RS <- db_resurv_RS %>%
  mutate(EUNIS1_conf_type = case_when(
    EUNISa_1 == "R" & EUNISb_1 == "S" ~ "R/S",
    EUNISa_1 == "S" & EUNISb_1 == "T" ~ "S/T",
    EUNISa_1 == "R" & EUNISb_1 == "R" & EUNISc_1 == "S" ~ "R/S",
    EUNISa_1 == "R" & EUNISb_1 == "R" & EUNISc_1 == "S" & EUNISd_1 == "S" ~ "R/S",
    EUNISa_1 == "P" & EUNISb_1 == "Q" ~ "P/Q",
    TRUE ~ NA_character_),
    EUNIS1_conf = !is.na(EUNIS1_conf_type))
```

## Tibble with selected columns

```{r}
db_resurv_RS_short <- db_resurv_RS %>%
  select(PlotObservationID, Country, RS_CODE, `ReSurvey site`, `ReSurvey plot`,
         `Manipulate (y/n)`, `Type of manipulation`, Lon_updated, Lat_updated,
         `Location method`, `Location uncertainty (m)`, 
         # Only considering EUNISa (i.e. first EUNIS assigned) so far
         EUNISa_1, EUNISa_1_descr, EUNISa_2, EUNISa_2_descr, EUNISa_3,
         EUNISa_3_descr, EUNISa_4, EUNISa_4_descr, EUNIS1_conf, 
         EUNIS1_conf_type, EUNIS_assignation, date, year, biogeo, unit, year_RS,
         Lon_RS, Lat_RS, 
         # All RS variables (indices + phenology)
         starts_with("NDVI"), starts_with("NDMI"), starts_with("NDWI"),
         starts_with("EVI"), starts_with("SAVI"), canopy_height,
         # T/F variables
         S2_data, S2_phen_data, RS_data, RS_phen_data, CH_data)
```

## TO-DO: Missing data checks

Do when all RS data is ready!

## Flag when year is different between RS data and ReSurvey db

```{r}
db_resurv_RS_short <- db_resurv_RS_short %>%
  mutate(year_diff = year != year_RS)
```

```{r}
db_resurv_RS_short %>% count(year_diff)
```

None with different year so far.

## Flag when coordinates are different between RS data and ReSurvey db

```{r}
db_resurv_RS_short <- db_resurv_RS_short %>%
  mutate(Lon_diff = case_when(Lon_updated == Lon_RS ~ "NO",
                              # Sometimes they are only slighly different
                              abs(Lon_updated - Lon_RS) < 0.01 ~ "SMALL",
                              is.na(Lon_updated) | is.na(Lon_RS) ~ NA,
                              TRUE ~ "LARGE"),
         Lat_diff = case_when(Lat_updated == Lat_RS ~ "NO",
                              # Sometimes they are only slighly different
                              abs(Lat_updated - Lat_RS) < 0.01 ~ "SMALL",
                              is.na(Lat_updated) | is.na(Lat_RS) ~ NA,
                              TRUE ~ "LARGE"))
```

```{r}
db_resurv_RS_short %>% count(Lon_diff)
db_resurv_RS_short %>% count(Lat_diff)
```

None with differences.

Remove unneeded vars:

```{r}
db_resurv_RS_short <- db_resurv_RS_short %>%
  select(-year_RS, -Lon_RS, -Lat_RS, -year_diff, -Lon_diff, -Lat_diff)
```

## Handle plots that have more than one obs per year

Add column PLOT to data to identify unique plots:

```{r}
db_resurv_RS_short_PLOT <- db_resurv_RS_short %>%
  # Original names give problems, create new vars
  mutate(RS_site = `ReSurvey site`, RS_plot = `ReSurvey plot`) %>%
  # Convert to data.table for faster processing
  lazy_dt() %>%
  # Group by the 3 vars that uniquely identify each plot
  group_by(RS_CODE, RS_site, RS_plot) %>%
  # Create a new variable PLOT for each group
  mutate(PLOT = .GRP) %>%
  # Convert back to tibble
  as_tibble() %>%
  # Remove unneeded vars
  select(-RS_site, -RS_plot)
```

There should be only one observation of each plot per year.

Plots where there is at least a year with more than one observation, and where those observations have a different EUNIS assigned:

```{r}
plots_to_remove <- db_resurv_RS_short_PLOT %>%
  group_by(PLOT, year) %>%
  summarize(EUNISa_1_n = n_distinct(EUNISa_1, na.rm = TRUE)) %>%
  ungroup() %>% 
  filter(EUNISa_1_n > 1) %>%
  distinct(PLOT)
```

Remove plots_to_remove from the database:

```{r}
db_resurv_RS_short_PLOT <- db_resurv_RS_short_PLOT %>%
  anti_join(plots_to_remove, by = "PLOT")
```

Plots and years where there is more than one observation:

```{r}
plots_to_merge <- db_resurv_RS_short_PLOT %>%
  group_by(PLOT, year) %>%
  # Plots that have more than one observation per year
  filter(n() > 1) %>%
  ungroup() %>%
  distinct(PLOT)
```

Summarize plots_to_merge:

```{r}
plots_to_merge_summ <- db_resurv_RS_short_PLOT %>%
  group_by(PLOT, year) %>%
  # Plots that have more than one observation per year
  filter(n() > 1) %>%
  mutate(obs_num = row_number()) %>%
  pivot_wider(
    names_from = obs_num,
    values_from = c(date, PlotObservationID),
    names_prefix = "obs_"
  ) %>%
  arrange(PLOT) %>%
  summarize(
    across(c(Country, RS_CODE, `ReSurvey site`, `ReSurvey plot`,
             `Manipulate (y/n)`, `Type of manipulation`, Lon_updated,
             Lat_updated, `Location method`, `Location uncertainty (m)`,
             EUNISa_1, EUNISa_1_descr, EUNISa_2, EUNISa_2_descr, EUNISa_3,
             EUNISa_3_descr, EUNISa_4, EUNISa_4_descr, EUNIS1_conf,
             EUNIS1_conf_type, EUNIS_assignation, biogeo, unit,
             starts_with("NDVI"), starts_with("NDMI"), starts_with("NDWI"),
             starts_with("SAVI"), starts_with("EVI"), canopy_height, S2_data,
             S2_phen_data, RS_data, RS_phen_data, CH_data), 
           # Function that gets the first non-NA value
           function(x) {
             x[which(!is.na(x))[1]]
             }
           ),
    across(starts_with("date_obs_"), min),
    across(starts_with("PlotObservationID_obs_"), min)
    ) %>%
  ungroup()
```

Remove plots_to_merge from the database:

```{r}
db_resurv_RS_short_PLOT <- db_resurv_RS_short_PLOT %>%
  filter(!(PLOT %in% plots_to_merge$PLOT))
```

And add plots_to_merge_summ, where each plot and year only has one row:

```{r}
db_resurv_RS_short_PLOT <- bind_rows(db_resurv_RS_short_PLOT,
                                     plots_to_merge_summ)
```

Check that there is only one row per plot and per year:

```{r}
db_resurv_RS_short_PLOT %>%
  group_by(PLOT, year) %>%
  # Plots that have more than one observation per year
  filter(n() > 1) 
```

So, to sum up what I have done:

- Plots where there is at least a year with more than one observation, and where those observations have a different EUNIS assigned: Plots REMOVED from the data
- Plots where there is more than one observation, but observations have the same EUNIS assigned: kept in the data. Merged so that there is only one row per year. Info about the different dates (when different) is kept in columns date_obs_1 - date_obs_40, and info about the different PlotObservationID is kept in the columns PlotObservationID_obs_1 - PlotObservationID_obs_40.

### Save to clean data

Save clean file for analyses (to be updated continuously due to updates in ReSurvey database and updates on RS data).

```{r}
write_tsv(db_resurv_RS_short_PLOT,
          here("data", "clean","db_resurv_RS_short_PLOT_20250617.csv"))
```

# Distributions all bioregions

```{r}
# Define a function to create histograms
plot_histogram <- function(data, x_var, x_label) {
  ggplot(data %>%
           filter(EUNISa_1 %in% c("T", "R", "S", "Q")),
         aes(x = !!sym(x_var))) +
    geom_histogram(color = "black", fill = "white") +
    labs(x = x_label, y = "Frequency") +
    theme_bw()
}
```

```{r}
# Define a function to create plots with violin + boxplot + points
distr_plot <- function(data, y_vars, y_labels) {
  for (i in seq_along(y_vars)) {
    y_var <- y_vars[[i]]
    y_label <- y_labels[[i]]
    
    p <- ggplot(data = data %>%
                  filter(EUNISa_1 %in% c("T", "R", "S", "Q")),
                aes(x = EUNISa_1_descr, y = !!sym(y_var), fill = EUNISa_1_descr)) +
      geom_flat_violin(position = position_nudge(x = 0.2, y = 0), alpha = 0.8) +
      geom_point(aes(y = !!sym(y_var), color = EUNISa_1_descr),
                 position = position_jitter(width = 0.15), size = 1, alpha = 0.25) +
      geom_boxplot(width = 0.2, outlier.shape = NA, alpha = 0.5) +
      stat_summary(fun.y = mean, geom = "point", shape = 20, size = 1) +
      stat_summary(fun.data = function(x) data.frame(y = max(x) + 0.1,
                                                     label = length(x)),
                   geom = "text", aes(label = ..label..), vjust = 0.5) +
      labs(y = y_label, x = "EUNIS level 1") +
      scale_x_discrete(labels = function(x) str_wrap(x, width = 15)) +
      guides(fill = FALSE, color = FALSE) +
      theme_bw() + coord_flip()
    
    print(p)
  }
}
```

## Indices (Landsat / S2)

Ranges of min and max:

```{r}
range(db_resurv_RS_short_PLOT$NDVI_max, na.rm = T)
range(db_resurv_RS_short_PLOT$NDMI_max, na.rm = T)
range(db_resurv_RS_short_PLOT$NDWI_max, na.rm = T)
range(db_resurv_RS_short_PLOT$SAVI_max, na.rm = T) # SAVI_max > 1!
range(db_resurv_RS_short_PLOT$EVI_max, na.rm = T) # EVI_max > 1!
range(db_resurv_RS_short_PLOT$NDVI_min, na.rm = T)
range(db_resurv_RS_short_PLOT$NDMI_min, na.rm = T)
range(db_resurv_RS_short_PLOT$NDWI_min, na.rm = T)
range(db_resurv_RS_short_PLOT$SAVI_min, na.rm = T)
range(db_resurv_RS_short_PLOT$EVI_min, na.rm = T) # EVI_min > 1!
```

```{r}
nrow(db_resurv_RS_short_PLOT %>% filter(NDVI_max > 1))
nrow(db_resurv_RS_short_PLOT %>% filter(NDMI_max > 1))
nrow(db_resurv_RS_short_PLOT %>% filter(NDWI_max > 1))
nrow(db_resurv_RS_short_PLOT %>% filter(SAVI_max > 1))
nrow(db_resurv_RS_short_PLOT %>% filter(EVI_max > 1))
nrow(db_resurv_RS_short_PLOT %>% filter(NDVI_min > 1))
nrow(db_resurv_RS_short_PLOT %>% filter(NDMI_min > 1))
nrow(db_resurv_RS_short_PLOT %>% filter(NDWI_min > 1))
nrow(db_resurv_RS_short_PLOT %>% filter(SAVI_min > 1))
nrow(db_resurv_RS_short_PLOT %>% filter(EVI_min > 1))
```

Histograms to check that max and min values are ok:

```{r}
plot_histogram(db_resurv_RS_short_PLOT, "NDVI_max", "NDVI max")
plot_histogram(db_resurv_RS_short_PLOT, "NDMI_max", "NDMI max")
plot_histogram(db_resurv_RS_short_PLOT, "NDWI_max", "NDWI max")
plot_histogram(db_resurv_RS_short_PLOT, "SAVI_max", "SAVI max")
plot_histogram(db_resurv_RS_short_PLOT %>% 
                 # Some values wrong!
                 filter(EVI_max <= 1), "EVI_max", "EVI max")
plot_histogram(db_resurv_RS_short_PLOT, "NDVI_min", "NDVI min")
plot_histogram(db_resurv_RS_short_PLOT, "NDMI_min", "NDMI min")
plot_histogram(db_resurv_RS_short_PLOT, "NDWI_min", "NDWI min")
plot_histogram(db_resurv_RS_short_PLOT, "SAVI_min", "SAVI min")
plot_histogram(db_resurv_RS_short_PLOT %>% 
                 # Some values wrong!
                 filter(EVI_min >= -1 & EVI_min <= 1), "EVI_min", "EVI min")
```

```{r}
nrow(db_resurv_RS_short_PLOT %>%
       filter(EUNISa_1 %in% c("T", "R", "S", "Q")) %>%
       filter(EVI_max > 1))
db_resurv_RS_short_PLOT %>%
       filter(EUNISa_1 %in% c("T", "R", "S", "Q"))%>%
  filter(EVI_max > 1) %>%
  count(biogeo, unit)
```

So far, do not use EVI values because they seem to be wrong. 

Distribution plots:

```{r message=FALSE, warning=FALSE}
distr_plot(db_resurv_RS_short_PLOT,
           c("NDVI_max", "NDVI_p90", "NDVI_mean", "NDVI_min", "NDVI_p10"), 
           c("NDVI max", "NDVI p90", "NDVI mean", "NDVI min", "NDVI p10"))
distr_plot(db_resurv_RS_short_PLOT,
           c("NDMI_max", "NDMI_p90", "NDMI_mean", "NDMI_min", "NDMI_p10"), 
           c("NDMI max", "NDMI p90", "NDMI mean", "NDMI min", "NDMI p10"))
distr_plot(db_resurv_RS_short_PLOT,
           c("NDWI_max", "NDWI_p90", "NDWI_mean", "NDWI_min", "NDWI_p10"), 
           c("NDWI max", "NDWI p90", "NDWI mean", "NDWI min", "NDWI p10"))
distr_plot(db_resurv_RS_short_PLOT,
           c("SAVI_max", "SAVI_p90", "SAVI_mean", "SAVI_min", "SAVI_p10"), 
           c("SAVI max", "SAVI p90", "SAVI mean", "SAVI min", "SAVI p10"))
```

```{r}
# Define a function to create plots with violin + boxplot + points
# Faceted by S2_data
distr_plot_sensor <- function(data, y_vars, y_labels) {
  for (i in seq_along(y_vars)) {
    y_var <- y_vars[[i]]
    y_label <- y_labels[[i]]
    
    p <- ggplot(data = data %>%
                  filter(EUNISa_1 %in% c("T", "R", "S", "Q")),
                aes(x = EUNISa_1_descr, y = !!sym(y_var), fill = EUNISa_1_descr)) +
      geom_flat_violin(position = position_nudge(x = 0.2, y = 0), alpha = 0.8) +
      geom_point(aes(y = !!sym(y_var), color = EUNISa_1_descr),
                 position = position_jitter(width = 0.15), size = 1, alpha = 0.25) +
      geom_boxplot(width = 0.2, outlier.shape = NA, alpha = 0.5) +
      stat_summary(fun.y = mean, geom = "point", shape = 20, size = 1) +
      stat_summary(fun.data = function(x) data.frame(y = max(x) + 0.1,
                                                     label = length(x)),
                   geom = "text", aes(label = ..label..), vjust = 0.5) +
      labs(y = y_label, x = "EUNIS level 1") +
      scale_x_discrete(labels = function(x) str_wrap(x, width = 15)) +
      guides(fill = FALSE, color = FALSE) +
      theme_bw() + coord_flip() + facet_wrap(~ S2_data)
    
    print(p)
  }
}
```

Distribution plots by sensor:

```{r message=FALSE, warning=FALSE}
distr_plot_sensor(db_resurv_RS_short_PLOT,
           c("NDVI_max", "NDVI_p90", "NDVI_mean", "NDVI_min", "NDVI_p10"), 
           c("NDVI max", "NDVI p90", "NDVI mean", "NDVI min", "NDVI p10"))
distr_plot_sensor(db_resurv_RS_short_PLOT,
           c("NDMI_max", "NDMI_p90", "NDMI_mean", "NDMI_min", "NDMI_p10"), 
           c("NDMI max", "NDMI p90", "NDMI mean", "NDMI min", "NDMI p10"))
distr_plot_sensor(db_resurv_RS_short_PLOT,
           c("NDWI_max", "NDWI_p90", "NDWI_mean", "NDWI_min", "NDWI_p10"), 
           c("NDWI max", "NDWI p90", "NDWI mean", "NDWI min", "NDWI p10"))
distr_plot_sensor(db_resurv_RS_short_PLOT,
           c("SAVI_max", "SAVI_p90", "SAVI_mean", "SAVI_min", "SAVI_p10"), 
           c("SAVI max", "SAVI p90", "SAVI mean", "SAVI min", "SAVI p10"))
```

## Indices (Landsat)

Ranges of min and max:

```{r}
range(db_resurv_RS_short_PLOT$NDVI_max_Landsat, na.rm = T)
range(db_resurv_RS_short_PLOT$NDMI_max_Landsat, na.rm = T)
range(db_resurv_RS_short_PLOT$NDWI_max_Landsat, na.rm = T)
range(db_resurv_RS_short_PLOT$SAVI_max_Landsat, na.rm = T) # SAVI_max > 1!
range(db_resurv_RS_short_PLOT$EVI_max_Landsat, na.rm = T) # EVI_max > 1! And max is 3900 - clearly wrong!
range(db_resurv_RS_short_PLOT$NDVI_min_Landsat, na.rm = T)
range(db_resurv_RS_short_PLOT$NDMI_min_Landsat, na.rm = T)
range(db_resurv_RS_short_PLOT$NDWI_min_Landsat, na.rm = T)
range(db_resurv_RS_short_PLOT$SAVI_min_Landsat, na.rm = T)
range(db_resurv_RS_short_PLOT$EVI_min_Landsat, na.rm = T) # EVI_min > 1!
```

```{r}
nrow(db_resurv_RS_short_PLOT %>% filter(NDVI_max_Landsat > 1))
nrow(db_resurv_RS_short_PLOT %>% filter(NDMI_max_Landsat > 1))
nrow(db_resurv_RS_short_PLOT %>% filter(NDWI_max_Landsat > 1))
nrow(db_resurv_RS_short_PLOT %>% filter(SAVI_max_Landsat > 1))
nrow(db_resurv_RS_short_PLOT %>% filter(EVI_max_Landsat > 1))
nrow(db_resurv_RS_short_PLOT %>% filter(NDVI_min_Landsat > 1))
nrow(db_resurv_RS_short_PLOT %>% filter(NDMI_min_Landsat > 1))
nrow(db_resurv_RS_short_PLOT %>% filter(NDWI_min_Landsat > 1))
nrow(db_resurv_RS_short_PLOT %>% filter(SAVI_min_Landsat > 1))
nrow(db_resurv_RS_short_PLOT %>% filter(EVI_min_Landsat > 1))
```

Distribution plots:

```{r message=FALSE, warning=FALSE}
distr_plot(db_resurv_RS_short_PLOT,
           c("NDVI_max_Landsat", "NDVI_p90_Landsat", "NDVI_mean_Landsat",
             "NDVI_min_Landsat", "NDVI_p10_Landsat"), 
           c("NDVI max Landsat", "NDVI p90 Landsat", "NDVI mean Landsat",
             "NDVI min Landsat", "NDVI p10 Landsat"))
distr_plot(db_resurv_RS_short_PLOT,
           c("NDMI_max_Landsat", "NDMI_p90_Landsat", "NDMI_mean_Landsat",
             "NDMI_min_Landsat", "NDMI_p10_Landsat"), 
           c("NDMI max Landsat", "NDMI p90 Landsat", "NDMI mean Landsat",
             "NDMI min Landsat", "NDMI p10 Landsat"))
distr_plot(db_resurv_RS_short_PLOT,
           c("NDWI_max_Landsat", "NDWI_p90_Landsat", "NDWI_mean_Landsat",
             "NDWI_min_Landsat", "NDWI_p10_Landsat"), 
           c("NDWI max Landsat", "NDWI p90 Landsat", "NDWI mean Landsat",
             "NDWI min Landsat", "NDWI p10 Landsat"))
distr_plot(db_resurv_RS_short_PLOT,
           c("SAVI_max_Landsat", "SAVI_p90_Landsat", "SAVI_mean_Landsat",
             "SAVI_min_Landsat", "SAVI_p10_Landsat"), 
           c("SAVI max Landsat", "SAVI p90 Landsat", "SAVI mean Landsat",
             "SAVI min Landsat", "SAVI p10 Landsat"))
```

## Indices (S2)

Ranges of min and max:

```{r}
range(db_resurv_RS_short_PLOT$NDVI_max_S2, na.rm = T)
range(db_resurv_RS_short_PLOT$NDMI_max_S2, na.rm = T)
range(db_resurv_RS_short_PLOT$NDWI_max_S2, na.rm = T)
range(db_resurv_RS_short_PLOT$SAVI_max_S2, na.rm = T) # SAVI_max > 1!
range(db_resurv_RS_short_PLOT$EVI_max_S2, na.rm = T) # EVI_max > 1!
range(db_resurv_RS_short_PLOT$NDVI_min_S2, na.rm = T)
range(db_resurv_RS_short_PLOT$NDMI_min_S2, na.rm = T)
range(db_resurv_RS_short_PLOT$NDWI_min_S2, na.rm = T)
range(db_resurv_RS_short_PLOT$SAVI_min_S2, na.rm = T)
range(db_resurv_RS_short_PLOT$EVI_min_S2, na.rm = T) # EVI_min < - 1!
```

```{r}
nrow(db_resurv_RS_short_PLOT %>% filter(NDVI_max_S2 > 1))
nrow(db_resurv_RS_short_PLOT %>% filter(NDMI_max_S2 > 1))
nrow(db_resurv_RS_short_PLOT %>% filter(NDWI_max_S2 > 1))
nrow(db_resurv_RS_short_PLOT %>% filter(SAVI_max_S2 > 1))
nrow(db_resurv_RS_short_PLOT %>% filter(EVI_max_S2 > 1))
nrow(db_resurv_RS_short_PLOT %>% filter(NDVI_min_S2 > 1))
nrow(db_resurv_RS_short_PLOT %>% filter(NDMI_min_S2 > 1))
nrow(db_resurv_RS_short_PLOT %>% filter(NDWI_min_S2 > 1))
nrow(db_resurv_RS_short_PLOT %>% filter(SAVI_min_S2 > 1))
nrow(db_resurv_RS_short_PLOT %>% filter(EVI_min_S2 < -1))
```

Distribution plots:

```{r message=FALSE, warning=FALSE}
distr_plot(db_resurv_RS_short_PLOT,
           c("NDVI_max_S2", "NDVI_p90_S2", "NDVI_mean_S2",
             "NDVI_min_S2", "NDVI_p10_S2"), 
           c("NDVI max S2", "NDVI p90 S2", "NDVI mean S2",
             "NDVI min S2", "NDVI p10 S2"))
distr_plot(db_resurv_RS_short_PLOT,
           c("NDMI_max_S2", "NDMI_p90_S2", "NDMI_mean_S2",
             "NDMI_min_S2", "NDMI_p10_S2"), 
           c("NDMI max S2", "NDMI p90 S2", "NDMI mean S2",
             "NDMI min S2", "NDMI p10 S2"))
distr_plot(db_resurv_RS_short_PLOT,
           c("NDWI_max_S2", "NDWI_p90_S2", "NDWI_mean_S2",
             "NDWI_min_S2", "NDWI_p10_S2"), 
           c("NDWI max S2", "NDWI p90 S2", "NDWI mean S2",
             "NDWI min S2", "NDWI p10 S2"))
distr_plot(db_resurv_RS_short_PLOT,
           c("SAVI_max_S2", "SAVI_p90_S2", "SAVI_mean_S2",
             "SAVI_min_S2", "SAVI_p10_S2"), 
           c("SAVI max S2", "SAVI p90 S2", "SAVI mean S2",
             "SAVI min S2", "SAVI p10 S2"))
```

## CH

```{r}
distr_plot(db_resurv_RS_short_PLOT, "canopy_height", "Canopy height (m)")
```
 
### Show habitats with CH categories

```{r}
ggplot(db_resurv_RS_short_PLOT %>%
         # Keep only forests, grasslands, shrublands and wetlands
         filter(EUNISa_1 %in% c("T", "R", "S", "Q")) %>%
         mutate(CH_cat =
                  factor(
                    case_when(canopy_height == 0 ~ "0 m",
                              canopy_height > 0 & canopy_height <= 1 ~ "0-1 m",
                              canopy_height > 1 & canopy_height <=2 ~ "1-2 m",
                              canopy_height > 2 & canopy_height <=5 ~ "2-5 m",
                              canopy_height > 5 & canopy_height <=8 ~ "5-8 m",
                              canopy_height > 8 ~ "> 8 m",
                              is.na(canopy_height) ~ NA_character_),
                    levels = c(
                      "0 m", "0-1 m", "1-2 m", "2-5 m", "5-8 m", "> 8 m"))),
       aes(x = EUNISa_1_descr, fill = CH_cat)) +
  geom_bar() + theme_bw() + coord_flip() +
  scale_y_continuous(labels = label_number()) +
  scale_fill_viridis_d(direction = -1) +
  labs(x = "EUNIS level 1", fill = "Canopy height") +
  scale_x_discrete(labels = function(x) str_wrap(x, width = 15)) +
  theme(legend.position = c(0.8, 0.75),
        legend.direction = "vertical")
```

### Stats per habitat type

```{r}
db_resurv_RS_short_PLOT %>%
  # Keep only forests, grasslands, shrublands and wetlands
  filter(EUNISa_1 %in% c("T", "R", "S", "Q")) %>%
  group_by(EUNISa_1_descr) %>%
  summarise(across(canopy_height, list(
    mean = mean,
    median = median,
    sd = sd,
    min = min,
    max = max
    ), na.rm = TRUE))
```

## Phenology

Only using NDVI- and SAVI-based values so far.

### Checks

Maximum NDVI should be equal to value at peak?

```{r}
nrow(db_resurv_RS_short_PLOT %>% filter(NDVI_val_maxDOY != NDVI_max))
nrow(db_resurv_RS_short_PLOT %>% filter(NDVI_val_maxDOY_S2 != NDVI_max_S2))
nrow(db_resurv_RS_short_PLOT %>% filter(NDVI_val_maxDOY_Landsat != NDVI_max_Landsat))
```

Growing season duration (GSD) should be larger than 0 days.

```{r}
nrow(db_resurv_RS_short_PLOT %>% filter(NDVI_GSD < 0))
nrow(db_resurv_RS_short_PLOT %>% filter(NDVI_GSD_S2 < 0))
nrow(db_resurv_RS_short_PLOT %>% filter(NDVI_GSD_Landsat < 0))
nrow(db_resurv_RS_short_PLOT %>% filter(SAVI_GSD < 0))
nrow(db_resurv_RS_short_PLOT %>% filter(SAVI_GSD_S2 < 0))
nrow(db_resurv_RS_short_PLOT %>% filter(SAVI_GSD_Landsat < 0))
```

```{r}
ggplot(db_resurv_RS_short_PLOT %>% 
         mutate(NDVI_GSD_status = ifelse(NDVI_GSD < 0, "wrong", "ok")),
       aes(x = NDVI_GSD, fill = NDVI_GSD_status)) +
  geom_histogram(color = "black")
ggplot(db_resurv_RS_short_PLOT %>% 
         mutate(NDVI_GSD_S2_status = ifelse(NDVI_GSD_S2 < 0, "wrong", "ok")),
       aes(x = NDVI_GSD_S2, fill = NDVI_GSD_S2_status)) +
  geom_histogram(color = "black")
ggplot(db_resurv_RS_short_PLOT %>% 
         mutate(NDVI_GSD_Landsat_status = ifelse(NDVI_GSD_Landsat < 0, "wrong", "ok")),
       aes(x = NDVI_GSD_Landsat, fill = NDVI_GSD_Landsat_status)) +
  geom_histogram(color = "black")
ggplot(db_resurv_RS_short_PLOT %>% 
         mutate(SAVI_GSD_status = ifelse(SAVI_GSD < 0, "wrong", "ok")),
       aes(x = SAVI_GSD, fill = SAVI_GSD_status)) +
  geom_histogram(color = "black")
ggplot(db_resurv_RS_short_PLOT %>% 
         mutate(SAVI_GSD_S2_status = ifelse(SAVI_GSD_S2 < 0, "wrong", "ok")),
       aes(x = SAVI_GSD_S2, fill = SAVI_GSD_S2_status)) +
  geom_histogram(color = "black")
ggplot(db_resurv_RS_short_PLOT %>% 
         mutate(SAVI_GSD_Landsat_status = ifelse(SAVI_GSD_Landsat < 0, "wrong", "ok")),
       aes(x = SAVI_GSD_Landsat, fill = SAVI_GSD_Landsat_status)) +
  geom_histogram(color = "black")
```

Browning DOY should be later than peak DOY.

```{r}
nrow(db_resurv_RS_short_PLOT %>% filter(NDVI_browning_doy < NDVI_doy_max))
nrow(db_resurv_RS_short_PLOT %>% filter(NDVI_browning_doy_S2 < NDVI_doy_max_S2))
nrow(db_resurv_RS_short_PLOT %>% filter(NDVI_browning_doy_Landsat < NDVI_doy_max_Landsat))
nrow(db_resurv_RS_short_PLOT %>% filter(SAVI_browning_doy < SAVI_doy_max))
nrow(db_resurv_RS_short_PLOT %>% filter(SAVI_browning_doy_S2 < SAVI_doy_max_S2))
nrow(db_resurv_RS_short_PLOT %>% filter(SAVI_browning_doy_Landsat < SAVI_doy_max_Landsat))
```

```{r}
ggplot(db_resurv_RS_short_PLOT,
       aes(x = NDVI_doy_max, y = NDVI_browning_doy,
           color = NDVI_browning_doy < NDVI_doy_max)) +
  geom_abline(slope = 1, intercept = 0) +
  geom_point()
ggplot(db_resurv_RS_short_PLOT,
       aes(x = NDVI_doy_max_S2, y = NDVI_browning_doy_S2,
           color = NDVI_browning_doy_S2 < NDVI_doy_max_S2)) +
  geom_abline(slope = 1, intercept = 0) +
  geom_point()
ggplot(db_resurv_RS_short_PLOT,
       aes(x = NDVI_doy_max_Landsat, y = NDVI_browning_doy_Landsat,
           color = NDVI_browning_doy_Landsat < NDVI_doy_max_Landsat)) +
  geom_abline(slope = 1, intercept = 0) +
  geom_point()
ggplot(db_resurv_RS_short_PLOT,
       aes(x = SAVI_doy_max, y = SAVI_browning_doy,
           color = SAVI_browning_doy < SAVI_doy_max)) +
  geom_abline(slope = 1, intercept = 0) +
  geom_point()
ggplot(db_resurv_RS_short_PLOT,
       aes(x = SAVI_doy_max_S2, y = SAVI_browning_doy_S2,
           color = SAVI_browning_doy_S2 < SAVI_doy_max_S2)) +
  geom_abline(slope = 1, intercept = 0) +
  geom_point()
ggplot(db_resurv_RS_short_PLOT,
       aes(x = SAVI_doy_max_Landsat, y = SAVI_browning_doy_Landsat,
           color = SAVI_browning_doy_Landsat < SAVI_doy_max_Landsat)) +
  geom_abline(slope = 1, intercept = 0) +
  geom_point()
```

Browning DOY should be later than greening DOY.

```{r}
nrow(db_resurv_RS_short_PLOT %>% filter(NDVI_browning_doy < NDVI_greening_doy))
nrow(db_resurv_RS_short_PLOT %>% filter(NDVI_browning_doy_S2 < NDVI_greening_doy_S2))
nrow(db_resurv_RS_short_PLOT %>% filter(NDVI_browning_doy_Landsat < NDVI_greening_doy_Landsat))
nrow(db_resurv_RS_short_PLOT %>% filter(SAVI_browning_doy < SAVI_greening_doy))
nrow(db_resurv_RS_short_PLOT %>% filter(SAVI_browning_doy_S2 < SAVI_greening_doy_S2))
nrow(db_resurv_RS_short_PLOT %>% filter(SAVI_browning_doy_Landsat < SAVI_greening_doy_Landsat))
```

```{r}
ggplot(db_resurv_RS_short_PLOT,
       aes(x = NDVI_greening_doy, y = NDVI_browning_doy,
           color = NDVI_browning_doy < NDVI_greening_doy)) +
  geom_abline(slope = 1, intercept = 0) +
  geom_point()
ggplot(db_resurv_RS_short_PLOT,
       aes(x = NDVI_greening_doy_S2, y = NDVI_browning_doy_S2,
           color = NDVI_browning_doy_S2 < NDVI_greening_doy_S2)) +
  geom_abline(slope = 1, intercept = 0) +
  geom_point()
ggplot(db_resurv_RS_short_PLOT,
       aes(x = NDVI_greening_doy_Landsat, y = NDVI_browning_doy_Landsat,
           color = NDVI_browning_doy_Landsat < NDVI_greening_doy_Landsat)) +
  geom_abline(slope = 1, intercept = 0) +
  geom_point()
ggplot(db_resurv_RS_short_PLOT,
       aes(x = SAVI_greening_doy, y = SAVI_browning_doy,
           color = SAVI_browning_doy < SAVI_greening_doy)) +
  geom_abline(slope = 1, intercept = 0) +
  geom_point()
ggplot(db_resurv_RS_short_PLOT,
       aes(x = SAVI_greening_doy_S2, y = SAVI_browning_doy_S2,
           color = SAVI_browning_doy_S2 < SAVI_greening_doy_S2)) +
  geom_abline(slope = 1, intercept = 0) +
  geom_point()
ggplot(db_resurv_RS_short_PLOT,
       aes(x = SAVI_greening_doy_Landsat, y = SAVI_browning_doy_Landsat,
           color = SAVI_browning_doy_Landsat < SAVI_greening_doy_Landsat)) +
  geom_abline(slope = 1, intercept = 0) +
  geom_point()
```

Peak DOY should be later than greening DOY.

```{r}
nrow(db_resurv_RS_short_PLOT %>% filter(NDVI_doy_max < NDVI_greening_doy))
nrow(db_resurv_RS_short_PLOT %>% filter(NDVI_doy_max_S2 < NDVI_greening_doy_S2))
nrow(db_resurv_RS_short_PLOT %>% filter(NDVI_doy_max_Landsat < NDVI_greening_doy_Landsat))
nrow(db_resurv_RS_short_PLOT %>% filter(SAVI_doy_max < SAVI_greening_doy))
nrow(db_resurv_RS_short_PLOT %>% filter(SAVI_doy_max_S2 < SAVI_greening_doy_S2))
nrow(db_resurv_RS_short_PLOT %>% filter(SAVI_doy_max_Landsat < SAVI_greening_doy_Landsat))
```

```{r}
ggplot(db_resurv_RS_short_PLOT,
       aes(x = NDVI_greening_doy, y = NDVI_doy_max,
           color = NDVI_doy_max < NDVI_greening_doy)) +
  geom_abline(slope = 1, intercept = 0) +
  geom_point()
ggplot(db_resurv_RS_short_PLOT,
       aes(x = NDVI_greening_doy_S2, y = NDVI_doy_max_S2,
           color = NDVI_doy_max_S2 < NDVI_greening_doy_S2)) +
  geom_abline(slope = 1, intercept = 0) +
  geom_point()
ggplot(db_resurv_RS_short_PLOT,
       aes(x = NDVI_greening_doy_Landsat, y = NDVI_doy_max_Landsat,
           color = NDVI_doy_max_Landsat < NDVI_greening_doy_Landsat)) +
  geom_abline(slope = 1, intercept = 0) +
  geom_point()
ggplot(db_resurv_RS_short_PLOT,
       aes(x = SAVI_greening_doy, y = SAVI_doy_max,
           color = SAVI_doy_max < SAVI_greening_doy)) +
  geom_abline(slope = 1, intercept = 0) +
  geom_point()
ggplot(db_resurv_RS_short_PLOT,
       aes(x = SAVI_greening_doy_S2, y = SAVI_doy_max_S2,
           color = SAVI_doy_max_S2 < SAVI_greening_doy_S2)) +
  geom_abline(slope = 1, intercept = 0) +
  geom_point()
ggplot(db_resurv_RS_short_PLOT,
       aes(x = SAVI_greening_doy_Landsat, y = SAVI_doy_max_Landsat,
           color = SAVI_doy_max_Landsat < SAVI_greening_doy_Landsat)) +
  geom_abline(slope = 1, intercept = 0) +
  geom_point()
```

NDVI_skew_EOS (difference between the end and the peak of the season DOY) and NDVI_skew_SOS (difference between the peak and the start of the season DOY) should be larger than 0.

```{r}
nrow(db_resurv_RS_short_PLOT %>% filter(NDVI_skew_EOS < 0))
nrow(db_resurv_RS_short_PLOT %>% filter(NDVI_skew_EOS_S2 < 0))
nrow(db_resurv_RS_short_PLOT %>% filter(NDVI_skew_EOS_Landsat < 0))
nrow(db_resurv_RS_short_PLOT %>% filter(NDVI_skew_SOS < 0))
nrow(db_resurv_RS_short_PLOT %>% filter(NDVI_skew_SOS_S2 < 0))
nrow(db_resurv_RS_short_PLOT %>% filter(NDVI_skew_SOS_Landsat < 0))
nrow(db_resurv_RS_short_PLOT %>% filter(SAVI_skew_EOS < 0))
nrow(db_resurv_RS_short_PLOT %>% filter(SAVI_skew_EOS_S2 < 0))
nrow(db_resurv_RS_short_PLOT %>% filter(SAVI_skew_EOS_Landsat < 0))
nrow(db_resurv_RS_short_PLOT %>% filter(SAVI_skew_SOS < 0))
nrow(db_resurv_RS_short_PLOT %>% filter(SAVI_skew_SOS_S2 < 0))
nrow(db_resurv_RS_short_PLOT %>% filter(SAVI_skew_SOS_Landsat < 0))
```

```{r}
ggplot(db_resurv_RS_short_PLOT %>% 
         mutate(NDVI_skew_EOS_status = 
                  ifelse(NDVI_skew_EOS < 0, "wrong", "ok")),
       aes(x = NDVI_skew_EOS, fill = NDVI_skew_EOS_status)) +
  geom_histogram(color = "black")
ggplot(db_resurv_RS_short_PLOT %>% 
         mutate(NDVI_skew_EOS_S2_status = 
                  ifelse(NDVI_skew_EOS_S2 < 0, "wrong", "ok")),
       aes(x = NDVI_skew_EOS_S2, fill = NDVI_skew_EOS_S2_status)) +
  geom_histogram(color = "black")
ggplot(db_resurv_RS_short_PLOT %>% 
         mutate(NDVI_skew_EOS_Landsat_status = 
                  ifelse(NDVI_skew_EOS_Landsat < 0, "wrong", "ok")),
       aes(x = NDVI_skew_EOS_Landsat, fill = NDVI_skew_EOS_Landsat_status)) +
  geom_histogram(color = "black")
ggplot(db_resurv_RS_short_PLOT %>% 
         mutate(NDVI_skew_SOS_status = 
                  ifelse(NDVI_skew_SOS < 0, "wrong", "ok")),
       aes(x = NDVI_skew_SOS, fill = NDVI_skew_SOS_status)) +
  geom_histogram(color = "black")
ggplot(db_resurv_RS_short_PLOT %>% 
         mutate(NDVI_skew_SOS_S2_status = 
                  ifelse(NDVI_skew_SOS_S2 < 0, "wrong", "ok")),
       aes(x = NDVI_skew_SOS_S2, fill = NDVI_skew_SOS_S2_status)) +
  geom_histogram(color = "black")
ggplot(db_resurv_RS_short_PLOT %>% 
         mutate(NDVI_skew_SOS_Landsat_status = 
                  ifelse(NDVI_skew_SOS_Landsat < 0, "wrong", "ok")),
       aes(x = NDVI_skew_SOS, fill = NDVI_skew_SOS_Landsat_status)) +
  geom_histogram(color = "black")
ggplot(db_resurv_RS_short_PLOT %>% 
         mutate(SAVI_skew_EOS_status = 
                  ifelse(SAVI_skew_EOS < 0, "wrong", "ok")),
       aes(x = SAVI_skew_EOS, fill = SAVI_skew_EOS_status)) +
  geom_histogram(color = "black")
ggplot(db_resurv_RS_short_PLOT %>% 
         mutate(SAVI_skew_EOS_S2_status = 
                  ifelse(SAVI_skew_EOS_S2 < 0, "wrong", "ok")),
       aes(x = SAVI_skew_EOS_S2, fill = SAVI_skew_EOS_S2_status)) +
  geom_histogram(color = "black")
ggplot(db_resurv_RS_short_PLOT %>% 
         mutate(SAVI_skew_EOS_Landsat_status = 
                  ifelse(SAVI_skew_EOS_Landsat < 0, "wrong", "ok")),
       aes(x = SAVI_skew_EOS_Landsat, fill = SAVI_skew_EOS_Landsat_status)) +
  geom_histogram(color = "black")
ggplot(db_resurv_RS_short_PLOT %>% 
         mutate(SAVI_skew_SOS_status = ifelse(SAVI_skew_SOS < 0, "wrong", "ok")),
       aes(x = SAVI_skew_SOS, fill = SAVI_skew_SOS_status)) +
  geom_histogram(color = "black")
ggplot(db_resurv_RS_short_PLOT %>% 
         mutate(SAVI_skew_SOS_S2_status = ifelse(SAVI_skew_SOS_S2 < 0, "wrong", "ok")),
       aes(x = SAVI_skew_SOS_S2, fill = SAVI_skew_SOS_S2_status)) +
  geom_histogram(color = "black")
ggplot(db_resurv_RS_short_PLOT %>% 
         mutate(SAVI_skew_SOS_S2_status = ifelse(SAVI_skew_SOS_S2 < 0, "wrong", "ok")),
       aes(x = SAVI_skew_SOS_S2, fill = SAVI_skew_SOS_S2_status)) +
  geom_histogram(color = "black")
```

Values at browning should be lower than values at peak - OK!

```{r}
nrow(db_resurv_RS_short_PLOT %>% filter(NDVI_val_browning > NDVI_val_maxDOY))
nrow(db_resurv_RS_short_PLOT %>% filter(NDVI_val_browning_S2 > NDVI_val_maxDOY_S2))
nrow(db_resurv_RS_short_PLOT %>% filter(NDVI_val_browning_Landsat > NDVI_val_maxDOY_Landsat))
```

Values at greening should be lower than values at peak - OK!

```{r}
nrow(db_resurv_RS_short_PLOT %>% filter(NDVI_val_greening > NDVI_val_maxDOY))
nrow(db_resurv_RS_short_PLOT %>% filter(NDVI_val_greening_S2 > NDVI_val_maxDOY_S2))
nrow(db_resurv_RS_short_PLOT %>% filter(NDVI_val_greening_Landsat > NDVI_val_maxDOY_Landsat))
```

### OLD: Histograms phenology measures

```{r}
ggplot(data = db_resurv_RS_short_PLOT %>%
         # Keep only forests, grasslands, shrublands and wetlands
         filter(EUNISa_1 %in% c("T", "R", "S", "Q") & S2_phen_data == T) %>%
         pivot_longer(cols = c(SOS_DOY, Peak_DOY, EOS_DOY), names_to = "name",
                      values_to = "value"),
       aes(x = value)) +
  geom_histogram(fill = "white", color = "black") +
  facet_grid(biogeo ~ name, scales = "free_y") +
  theme_bw()
ggplot(data = db_resurv_RS_short_PLOT %>%
         # Keep only forests, grasslands, shrublands and wetlands
         filter(EUNISa_1 %in% c("T", "R", "S", "Q") & S2_phen_data == T) %>%
         pivot_longer(cols = c(NDVI_at_SOS, NDVI_at_Peak, NDVI_at_EOS),
                      names_to = "name", values_to = "value"),
       aes(x = value)) +
  geom_histogram(fill = "white", color = "black") +
  facet_grid(biogeo ~ name, scales = "free_y") +
  theme_bw()
ggplot(data = db_resurv_RS_short_PLOT %>%
         # Keep only forests, grasslands, shrublands and wetlands
         filter(EUNISa_1 %in% c("T", "R", "S", "Q") & S2_phen_data == T) %>%
         pivot_longer(cols = c(diff_Peak_SOS, diff_Peak_EOS),
                      names_to = "name", values_to = "value"),
       aes(x = value)) +
  geom_histogram(fill = "white", color = "black") +
  facet_grid(biogeo ~ name, scales = "free_y") +
  theme_bw()
ggplot(data = db_resurv_RS_short_PLOT %>%
         # Keep only forests, grasslands, shrublands and wetlands
         filter(EUNISa_1 %in% c("T", "R", "S", "Q") & S2_phen_data == T) %>%
         pivot_longer(cols = c(Season_Length),
                      names_to = "name", values_to = "value"),
       aes(x = value)) +
  geom_histogram(fill = "white", color = "black") +
  facet_grid(biogeo ~ name, scales = "free_y") +
  theme_bw()
```

### Distributions

```{r}
distr_plot(db_resurv_RS_short_PLOT,
           c("SOS_DOY","Peak_DOY", "EOS_DOY",
             "NDVI_at_SOS", "NDVI_at_Peak", "NDVI_at_EOS",
             "diff_Peak_SOS","diff_Peak_EOS", "Season_Length"),
           c("SOS DOY", "Peak DOY", "EOS DOY",
             "NDVI at SOS", "NDVI at Peak", "NDVI at EOS",
             "Difference Peak-SOS", "Difference Peak-EOS", "Season Length"))
```

# OLD: Distributions per bioregion

```{r}
# Define a function to create plots with violin + boxplot + points
distr_plot_biogeo <- function(data, y_vars, y_labels) {
  plots <- list()
  
  for (i in seq_along(y_vars)) {
    y_var <- y_vars[[i]]
    y_label <- y_labels[[i]]
    
    p <- ggplot(data = data %>%
                  filter(EUNISa_1 %in% c("T", "R", "S", "Q")),
                aes(x = EUNISa_1_descr, y = !!sym(y_var), fill = EUNISa_1_descr)) +
      geom_flat_violin(position = position_nudge(x = 0.2, y = 0), alpha = 0.8) +
      geom_point(aes(y = !!sym(y_var), color = EUNISa_1_descr),
                 position = position_jitter(width = 0.15), size = 1, alpha = 0.25) +
      geom_boxplot(width = 0.2, outlier.shape = NA, alpha = 0.5) +
      stat_summary(fun.y = mean, geom = "point", shape = 20, size = 1) +
      stat_summary(fun.data = function(x) data.frame(y = max(x) + 0.1,
                                                     label = length(x)),
                   geom = "text", aes(label = ..label..), vjust = 0.5) +
      labs(y = y_label, x = "EUNISa_1_descr") +
      scale_x_discrete(labels = function(x) str_wrap(x, width = 15)) +
      guides(fill = FALSE, color = FALSE) +
      theme_bw() + coord_flip() + facet_wrap(~ biogeo)
    
    plots[[y_var]] <- p
  }
  
  return(plots)
}
```

## NDVI, NDMI, NDWI, SAVI and EVI

Distribution plots:

```{r message=FALSE, warning=FALSE}
distr_plot_biogeo(db_resurv_RS_short_PLOT %>% filter(!is.na(biogeo)),
           c("NDVI_max", "NDVI_p90", "NDVI_min", "NDVI_p10"), 
           c("NDVI max", "NDVI p90", "NDVI min", "NDVI p10"))
distr_plot_biogeo(db_resurv_RS_short_PLOT %>% filter(!is.na(biogeo)),
           c("NDMI_max", "NDMI_p90", "NDMI_min", "NDMI_p10"), 
           c("NDMI max", "NDMI p90", "NDMI min", "NDMI p10"))
distr_plot_biogeo(db_resurv_RS_short_PLOT %>% filter(!is.na(biogeo)),
           c("NDWI_max", "NDWI_p90", "NDWI_min", "NDWI_p10"), 
           c("NDWI max", "NDWI p90", "NDWI min", "NDWI p10"))
distr_plot_biogeo(db_resurv_RS_short_PLOT %>% filter(!is.na(biogeo)),
           c("SAVI_max", "SAVI_p90", "SAVI_min", "SAVI_p10"), 
           c("SAVI max", "SAVI p90", "SAVI min", "SAVI p10"))
distr_plot_biogeo(db_resurv_RS_short_PLOT %>% filter(!is.na(biogeo)) %>%
             filter(EVI_max <= 1) %>%
             filter(EVI_min >= -1 & EVI_min <= 1),
           c("EVI_max", "EVI_p90", "EVI_min", "EVI_p10"), 
           c("EVI max", "EVI p90", "EVI min", "EVI p10"))
```

## CH

```{r}
distr_plot_biogeo(db_resurv_RS_short_PLOT, "canopy_height", "Canopy height (m)")
```

In this plot, those with biogeo = NA are those that do not have S2 or Landsat data (and thus biogeo has not been assigned), but have CH data. We should later assign a biogeo based on location. 

## Phenology

```{r}
distr_plot_biogeo(db_resurv_RS_short_PLOT %>% filter(!is.na(biogeo)),
                  c("SOS_DOY", "Peak_DOY", "EOS_DOY",
                    "NDVI_at_SOS", "NDVI_at_Peak", "NDVI_at_EOS",
                    "diff_Peak_SOS", "diff_Peak_EOS", "Season_Length"),
                  c("SOS DOY", "Peak DOY", "EOS DOY",
                    "NDVI at SOS", "NDVI at Peak", "NDVI at EOS",
                    "Difference Peak-SOS", "Difference Peak-EOS",
                    "Season Length"))
```

BOR missing because there is no phenology info for EUNISa_1 %in% c("T", "R", "S", "Q").

# Including PLOT (USE LATER?)

Summarize variables by plot:

```{r}
db_resurv_RS_short_PLOT_summ <- db_resurv_RS_short_PLOT %>%
  filter(EUNISa_1 %in% c("T", "R", "S", "Q")) %>%
  filter(S2_data == T | Landsat_data == T) %>%
  group_by(PLOT) %>%
  summarize(EUNIS1 = if_else(n_distinct(EUNISa_1) > 1, "Change",
                             unique(EUNISa_1)[1]),
            count = n(),
            across(starts_with("NDVI"), list(mean = mean, sd = sd),
                   .names = "{col}_{fn}"))

```

Maybe use later because now many plots have only one observation, probably because some Landsat data is missing?

# RF with all GPS points without first validation, Landsat data

```{r}
filtered_data0 <- db_resurv_RS_short_PLOT %>%
  filter(EUNISa_1 %in% c("T", "R", "S", "Q")) %>%
  mutate(EUNISa_1 = as.factor(EUNISa_1)) %>%
  filter(EVI_max <= 1 & EVI_min >= -1) %>%
  # Define new vars (should be defined somewhere else)
  mutate(NDVI_max_SOS = NDVI_val_maxDOY_Landsat - NDVI_val_greening_Landsat,
         NDVI_max_EOS = NDVI_val_maxDOY_Landsat - NDVI_val_browning_Landsat,
         SAVI_max_SOS = SAVI_val_maxDOY_Landsat - SAVI_val_greening_Landsat,
         SAVI_max_EOS = SAVI_val_maxDOY_Landsat - SAVI_val_browning_Landsat)
```

Split into training and test data sets.

```{r}
train_indices0 <- sample(1:nrow(filtered_data0), 0.7 * nrow(filtered_data0))
train_data0 <- filtered_data0[train_indices0, ]
test_data0 <- filtered_data0[-train_indices0, ]
```

Number of points per category for filtered data:

```{r}
filtered_data0 %>% count(EUNISa_1)
```

```{r}
rf_cforest0 <- party::cforest(EUNISa_1 ~ 
                                # max, mean and min NDVI
                                NDVI_max_Landsat + NDVI_mean_Landsat +
                                NDVI_min_Landsat +
                                # max, mean and min NDMI
                                NDMI_max_Landsat + NDMI_mean_Landsat +
                                NDMI_min_Landsat +
                                # max, mean and min NDWI
                                NDWI_max_Landsat + NDWI_mean_Landsat +
                                NDWI_min_Landsat +
                                # max, mean and min SAVI
                                SAVI_max_Landsat + SAVI_mean_Landsat +
                                SAVI_min_Landsat +
                                # NDVI-derived phenological vars
                                NDVI_val_browning_Landsat + 
                                NDVI_val_greening_Landsat +
                                NDVI_val_maxDOY_Landsat +
                                NDVI_skew_EOS_Landsat +
                                NDVI_skew_SOS_Landsat +
                                NDVI_skew_total_Landsat +
                                NDVI_max_SOS + NDVI_max_EOS +
                                # SAVI-derived phenological vars
                                SAVI_val_browning_Landsat + 
                                SAVI_val_greening_Landsat +
                                SAVI_val_maxDOY_Landsat +
                                SAVI_skew_EOS_Landsat +
                                SAVI_skew_SOS_Landsat +
                                SAVI_skew_total_Landsat +
                                SAVI_max_SOS + SAVI_max_EOS +
                                # CH
                                canopy_height,
                              data = train_data0,
                              controls = cforest_control(
                                mtry = 3,
                                # mtry = sqrt(11)
                                # Default mtry = 5
                                # Bagging: mtry = NULL
                                # or = number of input variables
                                ntree = 500) # Default, try increasing
                              ) 
```

```{r}
predictions_rf_cforest0 <- predict(rf_cforest0, newdata = test_data0,
                                   OOB = TRUE, type = "response")
```

Confusion matrix:

```{r}
confusionMatrix(predictions_rf_cforest0, test_data0$EUNISa_1)
```

```{r}
varimp_rf_cforest0 <- party::varimp(rf_cforest0, conditional = F) 
```

```{r eval=FALSE, include=FALSE}
varimp_rf_cond_cforest0 <- party::varimp(rf_cforest0, conditional = T)
# conditional = T adjusts for correlations between predictor variables
# Takes long!
save(varimp_rf_cond_cforest0, file = "objects/varimp_rf_cond_cforest0.Rdata")
```

Variable Importance Plot

```{r}
varimp_rf_cforest0_df <- data.frame(Variable = names(varimp_rf_cforest0),
                                    Importance = varimp_rf_cforest0)
ggplot(varimp_rf_cforest0_df,
       aes(x = reorder(Variable, Importance), y = Importance)) +
  geom_bar(stat = "identity", fill = "lightblue") +
  coord_flip() + theme_minimal() +
  labs(title = "Variable Importance", x = "Variables", y = "Importance")
```

ROC curves:

```{r}
# Predict probabilities for each class
probabilities <- predict(rf_cforest0, newdata = test_data0, type = "prob")

# Step 1: Convert list of matrices to a proper data frame
prob_matrix <- t(sapply(probabilities, as.vector))
colnames(prob_matrix) <- c("Q", "R", "S", "T")  # Adjust if needed
prob_df <- as.data.frame(prob_matrix)

# Step 2: Prepare actual class labels
actual <- factor(test_data0$EUNISa_1, levels = c("Q", "R", "S", "T"))
classes <- levels(actual)

# Step 3: Binarize actual labels
actual_bin <- model.matrix(~ actual - 1)
colnames(actual_bin) <- gsub("actual", "", colnames(actual_bin))

# Step 4: Compute ROC data for each class with AUC in label
roc_data <- lapply(classes, function(class) {
  roc_obj <- roc(actual_bin[, class], prob_df[[class]])
  auc_val <- round(auc(roc_obj), 3)
  data.frame(
    FPR = rev(roc_obj$specificities),
    TPR = rev(roc_obj$sensitivities),
    Class = paste0(class, " (AUC = ", auc_val, ")")
  )
}) %>% bind_rows()

# Step 5: Plot ROC curves with ggplot2
roc0 <- ggplot(roc_data, aes(x = FPR, y = TPR, color = Class)) +
  geom_line(size = 1.2) +
  geom_abline(linetype = "dashed", color = "gray") +
  labs(
    title = "Multiclass ROC Curves with AUC",
    x = "False Positive Rate",
    y = "True Positive Rate",
    color = "Class (AUC)"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")
roc0
```

# First validation

For T, R, S, Q habitats.

Define a set of rules for a first validation of ALL ReSurvey data. We can call these "Expert-based" rules.

Number of observations in ReSurvey from the habitats of interest:

```{r}
nrow(db_resurv_RS_short_PLOT %>%
       filter(EUNISa_1 %in% c("T", "R", "S", "Q")))
```

Number of observations in ReSurvey from the habitats of interest and with all RS data:

```{r}
nrow(db_resurv_RS_short_PLOT %>%
       filter(EUNISa_1 %in% c("T", "R", "S", "Q")) %>%
       filter(CH_data == T) %>%
       filter(RS_data ==T) %>%
       filter(RS_phen_data == T))
```

```{r}
db_resurv_RS_short_PLOT_terrestrial <- db_resurv_RS_short_PLOT %>%
  filter(EUNISa_1 %in% c("T", "R", "S", "Q"))
```

## Define rules

Create column for first validation based on different indicators, where "wrong" is noted when the validation rule is not met. Include EUNIS1 confusions.

```{r}
db_resurv_RS_short_PLOT_terrestrial %>% count(EUNISa_1, EUNIS1_conf_type)
```

Define rules:

```{r}
db_resurv_RS_short_PLOT_terrestrial <-
  db_resurv_RS_short_PLOT_terrestrial %>%
  mutate(
    valid_1_NDWI = case_when(
      # Points that are basically water
      NDWI_max > 0.3 ~ "wrong",
      TRUE ~ NA_character_),
    valid_1_CH = case_when(
      # T points with low CH
      EUNISa_1 == "T" & canopy_height < 8 ~ "wrong",
      # S points with low CH
      EUNISa_1 =="S" & canopy_height < 5 ~ "wrong",
      # R & Q points with high CH
      EUNISa_1 %in% c("R", "Q") & canopy_height > 2 ~ "wrong",
      TRUE ~ NA_character_),
    valid_1_NDVI = case_when(
      # T points with low NDVI_max
      EUNISa_1 == "T" & NDVI_max < 0.6 ~ "wrong",
      # S-R-Q points with low NDVI_max
      EUNISa_1 %in% c("R", "S", "Q") & NDVI_max < 0.2 ~ "wrong",
      TRUE ~ NA_character_),
    # Count how many validation rules are not met
    valid_1_count = rowSums(across(c(valid_1_NDWI, valid_1_CH, valid_1_NDVI), 
                             ~ . == "wrong"), na.rm = TRUE),
    # Points where at least 1 rule not met
    valid_1 = if_else(valid_1_count > 0, "At least 1 rule broken",
                      "No rules broken so far")
    )
```

## Plots first validation

```{r}
ggplot(db_resurv_RS_short_PLOT_terrestrial%>%
         mutate(rules_broken = case_when(
           valid_1_count == 1 & valid_1_NDWI == "wrong" ~ "NDWI",
           valid_1_count == 1 & valid_1_NDVI == "wrong" ~ "NDVI",
           valid_1_count == 1 & valid_1_CH == "wrong" ~ "CH",
           valid_1_count == 2 &
             valid_1_NDWI == "wrong" & valid_1_NDVI == "wrong"~ "NDWI + NDVI",
           valid_1_count == 2 &
             valid_1_NDWI == "wrong" & valid_1_CH == "wrong"~ "NDWI + CH",
           valid_1_count == 2 &
             valid_1_NDVI == "wrong" & valid_1_CH == "wrong"~ "NDVI + CH",
           valid_1_count == 3 ~ "NDWI + NDVI + CH",
           TRUE ~ NA_character_
         )), 
       aes(x = valid_1_count, fill = rules_broken)) +
  geom_bar() + labs(x = "Number of broken rules")
```

```{r}
db_resurv_RS_short_PLOT_terrestrial %>%
         mutate(rules_broken = case_when(
           valid_1_count == 1 & valid_1_NDWI == "wrong" ~ "NDWI",
           valid_1_count == 1 & valid_1_NDVI == "wrong" ~ "NDVI",
           valid_1_count == 1 & valid_1_CH == "wrong" ~ "CH",
           valid_1_count == 2 &
             valid_1_NDWI == "wrong" & valid_1_NDVI == "wrong"~ "NDWI + NDVI",
           valid_1_count == 2 &
             valid_1_NDWI == "wrong" & valid_1_CH == "wrong"~ "NDWI + CH",
           valid_1_count == 2 &
             valid_1_NDVI == "wrong" & valid_1_CH == "wrong"~ "NDVI + CH",
           valid_1_count == 3 ~ "NDWI + NDVI + CH",
           TRUE ~ NA_character_
         )) %>%
  count(rules_broken, EUNIS1_conf_type)
```

Proportion of observations not validated (so far):

```{r}
nrow(db_resurv_RS_short_PLOT_terrestrial %>% filter(valid_1_count > 0))/
  nrow(db_resurv_RS_short_PLOT_terrestrial)
```

But be aware that there are still MANY missing RS data.

```{r}
ggplot(db_resurv_RS_short_PLOT_terrestrial %>%
         mutate(diff_GPS = if_else(
           `Location method` != "Location with differential GPS" |
             is.na(`Location method`), "no", "yes")), 
       aes(x = diff_GPS, fill = valid_1)) +
  geom_bar() + labs(x = "Differential GPS")
ggplot(db_resurv_RS_short_PLOT_terrestrial %>%
         mutate(GPS = case_when(
           `Location method` == "Location with differential GPS" ~ "yes",
           `Location method` == "Location with GPS" ~ "yes",
           is.na(`Location method`) ~ "no",
           TRUE ~ "no"
         )), 
       aes(x = GPS, fill = valid_1)) +
  geom_bar() + labs(x = "GPS")
```

Points with any rule broken and confusion between EUNIS:

```{r}
nrow(db_resurv_RS_short_PLOT_terrestrial %>%
       filter(EUNIS1_conf == T & valid_1_count > 0))
```

Convert to shp to look at these in GIS:

```{r}
# st_write(db_resurv_RS_short_PLOT_terrestrial %>%
#            filter(EUNIS1_conf == T & valid_1_count > 0) %>%
#            st_as_sf(coords = c("Lon_updated", "Lat_updated"), crs = 4326),
#          "C:/GIS/MOTIVATE/shapefiles/resurv_not_val_EUNIS_conf.shp")
```

Checked and yes

How many points with differential GPS that have at least 1 rule broken?

```{r}
nrow(db_resurv_RS_short_PLOT_terrestrial %>%
  filter(`Location method` == "Location with differential GPS" &
           valid_1 == "At least 1 rule broken"))
```

Convert to shp to look at these in GIS:

```{r}
# st_write(db_resurv_RS_short_PLOT_terrestrial %>%
#            filter(`Location method` == "Location with differential GPS" &
#                     valid_1 == "At least 1 rule broken") %>%
#            st_as_sf(coords = c("Lon_updated", "Lat_updated"), crs = 4326),
#          "C:/GIS/MOTIVATE/shapefiles/resurv_not_val_diff_GPS.shp")
```

# Maps

## Points GPS

```{r}
# Load world boundaries
world <- ne_countries(scale = "medium", returnclass = "sf")

# Calculate the extent of the points
points_GPS_extent <- db_resurv_RS_short_PLOT %>%
  filter(EUNISa_1 %in% c("T", "R", "S", "Q")) %>%
  filter(S2_data == T | Landsat_data == T ) %>%
  filter(`Location method` == "Location with differential GPS" |
           `Location method` == "Location with GPS") %>%
  summarise(lon_min = min(Lon_updated, na.rm = TRUE),
            lon_max = max(Lon_updated, na.rm = TRUE),
            lat_min = min(Lat_updated, na.rm = TRUE),
            lat_max = max(Lat_updated, na.rm = TRUE))

# Add padding to the extent (adjust as needed)
padding <- 2  # Adjust padding to your preference
x_limits <- c(points_GPS_extent$lon_min - padding,
              points_GPS_extent$lon_max + padding)
y_limits <- c(points_GPS_extent$lat_min - padding,
              points_GPS_extent$lat_max + padding)

# Create the zoomed map
ggplot() +
  geom_sf(data = world, fill = "lightblue", color = "gray") +
  geom_point(data = db_resurv_RS_short_PLOT %>%
               filter(EUNISa_1 %in% c("T", "R", "S", "Q")) %>%
               filter(S2_data == T | Landsat_data == T ) %>%
               filter(`Location method` == "Location with differential GPS" |
           `Location method` == "Location with GPS"),
             aes(x = Lon_updated, y = Lat_updated, color = EUNISa_1),
             size = 1) +
  coord_sf(xlim = x_limits, ylim = y_limits) +
  theme_minimal()
```

Number of GPS points by Country:

```{r}
db_resurv_RS_short_PLOT %>%
  filter(EUNISa_1 %in% c("T", "R", "S", "Q")) %>%
  filter(S2_data == T | Landsat_data == T ) %>%
  filter(`Location method` == "Location with differential GPS" |
           `Location method` == "Location with GPS") %>%
  count(Country)
```

## Points ReSurvey

```{r}
# Calculate the extent of the points
points_resurvey_extent <- db_resurv_RS_short_PLOT %>%
  filter(EUNISa_1 %in% c("T", "R", "S", "Q")) %>%
  filter(S2_data == T | Landsat_data == T ) %>%
  summarise(lon_min = min(Lon_updated, na.rm = TRUE),
            lon_max = max(Lon_updated, na.rm = TRUE),
            lat_min = min(Lat_updated, na.rm = TRUE),
            lat_max = max(Lat_updated, na.rm = TRUE))

# Add padding to the extent (adjust as needed)
padding <- 2  # Adjust padding to your preference
x_limits <- c(points_resurvey_extent$lon_min - padding,
              points_resurvey_extent$lon_max + padding)
y_limits <- c(points_resurvey_extent$lat_min - padding,
              points_resurvey_extent$lat_max + padding)

# Create the zoomed map
ggplot() +
  geom_sf(data = world, fill = "lightblue", color = "gray") +
  geom_point(data = db_resurv_RS_short_PLOT %>%
               filter(EUNISa_1 %in% c("T", "R", "S", "Q")) %>%
               filter(S2_data == T | Landsat_data == T ),
             aes(x = Lon_updated, y = Lat_updated, color = EUNISa_1),
             size = 1) +
  coord_sf(xlim = x_limits, ylim = y_limits) +
  theme_minimal()
```

Number of ReSurvey points by Country:

```{r}
db_resurv_RS_short_PLOT %>%
  filter(EUNISa_1 %in% c("T", "R", "S", "Q")) %>%
  filter(S2_data == T | Landsat_data == T ) %>%
  count(Country)
```

# Distributions from GPS points without rules broken so far

Create tibble with differential GPS points without rules broken so far:

```{r}
all_GPS_valid <- db_resurv_RS_short_PLOT_terrestrial %>%
  filter((`Location method` == "Location with differential GPS" | 
            `Location method` == "Location with GPS" ) &
           valid_1 == "No rules broken so far") 
```

## NDVI, NDMI, NDWI, SAVI and EVI

```{r}
distr_plot(all_GPS_valid,
           c("NDVI_max", "NDVI_p90", "NDVI_min", "NDVI_p10"), 
           c("NDVI max", "NDVI p90", "NDVI min", "NDVI p10"))
distr_plot(all_GPS_valid,
           c("NDMI_max", "NDMI_p90", "NDMI_min", "NDMI_p10"), 
           c("NDMI max", "NDMI p90", "NDMI min", "NDMI p10"))
distr_plot(all_GPS_valid,
           c("NDWI_max", "NDWI_p90", "NDWI_min", "NDWI_p10"), 
           c("NDWI max", "NDWI p90", "NDWI min", "NDWI p10"))
distr_plot(all_GPS_valid,
           c("SAVI_max", "SAVI_p90", "SAVI_min", "SAVI_p10"), 
           c("SAVI max", "SAVI p90", "SAVI min", "SAVI p10"))
distr_plot(all_GPS_valid %>%
             filter(EVI_max <= 1) %>%
             filter(EVI_min >= -1 & EVI_min <= 1),
           c("EVI_max", "EVI_p90", "EVI_min", "EVI_p10"), 
           c("EVI max", "EVI p90", "EVI min", "EVI p10"))
```

## CH

```{r}
distr_plot(all_GPS_valid, "canopy_height", "Canopy height (m)")
```

## Phenology

```{r}
distr_plot(all_GPS_valid,
           c("SOS_DOY","Peak_DOY", "EOS_DOY",
             "NDVI_at_SOS", "NDVI_at_Peak", "NDVI_at_EOS",
             "diff_Peak_SOS","diff_Peak_EOS", "Season_Length"),
           c("SOS DOY", "Peak DOY", "EOS DOY",
             "NDVI at SOS", "NDVI at Peak", "NDVI at EOS",
             "Difference Peak-SOS", "Difference Peak-EOS", "Season Length"))
```

# GPS valid points above p20 of NDVI_max and NDMI_min for each habitat

# HERE! 

Chosen NDVI_min because it was important in RF models, but let's see with new data!

```{r}
percentiles_all_GPS <- all_GPS_valid %>%
  group_by(EUNISa_1) %>%
  summarize(percentile_20_NDVI_max = quantile(NDVI_max, probs = 0.20, na.rm = T),
            percentile_20_NDMI_min = quantile(NDMI_min, probs = 0.20, na.rm = T))

all_GPS_valid <- all_GPS_valid %>%
  left_join(percentiles_all_GPS, by = "EUNISa_1") %>%
  mutate(category_NDVI_max = case_when(
    NDVI_max < percentile_20_NDVI_max ~ "below_20th",
    NDVI_max >= percentile_20_NDVI_max ~ "above_20th"),
  category_NDMI_min = case_when(
    NDMI_min < percentile_20_NDMI_min ~ "below_20th",
    NDMI_min >= percentile_20_NDMI_min ~ "above_20th"))

ggplot(data = all_GPS_valid,
       aes(x = EUNISa_1_descr, y = NDVI_max)) +
  geom_flat_violin(position = position_nudge(x = 0.2, y = 0), alpha = 0.8,
                   fill = "lightblue") +
  geom_point(aes(color = category_NDVI_max),
             position = position_jitter(width = 0.15), size = 1, alpha = 0.25) +
  geom_boxplot(width = 0.2, outlier.shape = NA, alpha = 0.5) +
  stat_summary(fun.y = mean, geom = "point", shape = 20, size = 1) +
  stat_summary(fun.data = function(x) data.frame(y = max(x) + 0.1, label = length(x)),
               geom = "text", aes(label = ..label..), vjust = 0.5) +
  labs(y = "NDVI max", x = "EUNIS level 1") +
  guides(fill = FALSE, color = FALSE) +
  scale_x_discrete(labels = function(x) str_wrap(x, width = 15)) +
  scale_color_manual(values = c("below_20th" = "grey", "above_20th" = "lightblue")) +
  theme_bw() + coord_flip()

ggplot(data = all_GPS_valid,
       aes(x = EUNISa_1_descr, y = NDMI_min)) +
  geom_flat_violin(position = position_nudge(x = 0.2, y = 0), alpha = 0.8,
                   fill = "lightblue") +
  geom_point(aes(color = category_NDMI_min),
             position = position_jitter(width = 0.15), size = 1, alpha = 0.25) +
  geom_boxplot(width = 0.2, outlier.shape = NA, alpha = 0.5) +
  stat_summary(fun.y = mean, geom = "point", shape = 20, size = 1) +
  stat_summary(fun.data = function(x) data.frame(y = max(x) + 0.1, label = length(x)),
               geom = "text", aes(label = ..label..), vjust = 0.5) +
  labs(y = "NDMI min", x = "EUNIS level 1") +
  guides(fill = FALSE, color = FALSE) +
  scale_x_discrete(labels = function(x) str_wrap(x, width = 15)) +
  scale_color_manual(values = c("below_20th" = "grey", "above_20th" = "lightblue")) +
  theme_bw() + coord_flip()
```

# RF models

Using the conditional inference version of random forest (cforest in package party). Suggested if the data are highly correlated. Cforest is more stable in deriving variable importance values in the presence of highly correlated variables, thus providing better accuracy in calculating variable importance (ref below).

Hothorn, T., Hornik, K. and Zeileis, A. (2006) Unbiased Recursive Portioning: A Conditional Inference Framework. Journal of Computational and Graphical Statistics, 15, 651-
674. http://dx.doi.org/10.1198/106186006X133933

## All GPS points

```{r}
filtered_data0 <- all_GPS_valid %>%
  filter(!is.na(NDVI_max) & !is.na(NDMI_max) & !is.na(NDWI_max) &
           !is.na(SAVI_max) & !is.na(EVI_max) & !is.na(NDVI_min) &
           !is.na(NDMI_min) & !is.na(NDWI_min) & !is.na(SAVI_min) &
           !is.na(EVI_min)) %>%
  mutate(EUNISa_1 = as.factor(EUNISa_1)) %>%
  filter(EVI_max <= 1 & EVI_min >= -1)
```

Split into training and test data sets.

```{r}
train_indices0 <- sample(1:nrow(filtered_data0), 0.7 * nrow(filtered_data0))
train_data0 <- filtered_data0[train_indices0, ]
test_data0 <- filtered_data0[-train_indices0, ]
```

Number of points per category for filtered data:

```{r}
filtered_data0 %>% count(EUNISa_1)
```

```{r}
rf_cforest0 <- party::cforest(EUNISa_1 ~ NDVI_max + NDVI_min + NDMI_max +
                                NDMI_min + NDWI_max + NDWI_min + EVI_max +
                                EVI_min + SAVI_max + SAVI_min + canopy_height, 
                              data = train_data0,
                              controls = cforest_control(
                                mtry = 3,
                                # mtry = sqrt(11)
                                # Default mtry = 5
                                # Bagging: mtry = NULL
                                # or = number of input variables
                                ntree = 500) # Default, try increasing
                              ) 
```

```{r}
predictions_rf_cforest0 <- predict(rf_cforest0, newdata = test_data0,
                                   OOB = TRUE, type = "response")
```

Confusion matrix:

```{r}
confusionMatrix(predictions_rf_cforest0, test_data0$EUNISa_1)
```

```{r}
varimp_rf_cforest0 <- party::varimp(rf_cforest0, conditional = F) 
```

```{r eval=FALSE, include=FALSE}
varimp_rf_cond_cforest0 <- party::varimp(rf_cforest0, conditional = T)
# conditional = T adjusts for correlations between predictor variables
# Takes long!
save(varimp_rf_cond_cforest0, file = "objects/varimp_rf_cond_cforest0.Rdata")
```

Variable Importance Plot

```{r}
varimp_rf_cforest0_df <- data.frame(Variable = names(varimp_rf_cforest0),
                                    Importance = varimp_rf_cforest0)
ggplot(varimp_rf_cforest0_df,
       aes(x = reorder(Variable, Importance), y = Importance)) +
  geom_bar(stat = "identity", fill = "lightblue") +
  coord_flip() + theme_minimal() +
  labs(title = "Variable Importance", x = "Variables", y = "Importance")
```

ROC curves:

```{r}
# Predict probabilities for each class
probabilities <- predict(rf_cforest0, newdata = test_data0, type = "prob")

# Step 1: Convert list of matrices to a proper data frame
prob_matrix <- t(sapply(probabilities, as.vector))
colnames(prob_matrix) <- c("Q", "R", "S", "T")  # Adjust if needed
prob_df <- as.data.frame(prob_matrix)

# Step 2: Prepare actual class labels
actual <- factor(test_data0$EUNISa_1, levels = c("Q", "R", "S", "T"))
classes <- levels(actual)

# Step 3: Binarize actual labels
actual_bin <- model.matrix(~ actual - 1)
colnames(actual_bin) <- gsub("actual", "", colnames(actual_bin))

# Step 4: Compute ROC data for each class with AUC in label
roc_data <- lapply(classes, function(class) {
  roc_obj <- roc(actual_bin[, class], prob_df[[class]])
  auc_val <- round(auc(roc_obj), 3)
  data.frame(
    FPR = rev(roc_obj$specificities),
    TPR = rev(roc_obj$sensitivities),
    Class = paste0(class, " (AUC = ", auc_val, ")")
  )
}) %>% bind_rows()

# Step 5: Plot ROC curves with ggplot2
roc0 <- ggplot(roc_data, aes(x = FPR, y = TPR, color = Class)) +
  geom_line(size = 1.2) +
  geom_abline(linetype = "dashed", color = "gray") +
  labs(
    title = "Multiclass ROC Curves with AUC",
    x = "False Positive Rate",
    y = "True Positive Rate",
    color = "Class (AUC)"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")
roc0
```

## REVISE FROM HERE: All GPS points above p20

Filter the data to get only GPS-points above p20 of NDVI_max and NDMI_min.

```{r}
all_GPS_valid <- all_GPS_valid %>%
  select(-percentile_20_NDVI_max, -percentile_20_NDMI_min)
```

```{r}
percentiles <- all_GPS_valid %>%
  group_by(EUNISa_1) %>%
  summarize(
    percentile_20_NDVI_max = quantile(NDVI_max, 0.20, na.rm = T),
    percentile_20_NDMI_min = quantile(NDMI_min, 0.20, na.rm = T),
    percentile_80_NDVI_max = quantile(NDVI_max, 0.80, na.rm = T),
    percentile_80_NDMI_min = quantile(NDMI_min, 0.80, na.rm = T)
    )

# Join the percentiles back to the original data
all_GPS_valid <- all_GPS_valid %>%
  left_join(percentiles, by = "EUNISa_1")

# Filter rows above the 20th percentile for both variables for each category of EUNISa_1
filtered_data1 <- all_GPS_valid %>%
  filter(
    NDVI_max >= percentile_20_NDVI_max & NDMI_min >= percentile_20_NDMI_min
    ) %>%
  filter(!is.na(NDVI_max) & !is.na(NDMI_max) & !is.na(NDWI_max) &
           !is.na(SAVI_max) & !is.na(EVI_max) & !is.na(NDVI_min) &
           !is.na(NDMI_min) & !is.na(NDWI_min) & !is.na(SAVI_min) &
           !is.na(EVI_min)) %>%
  mutate(EUNISa_1 = as.factor(EUNISa_1)) %>%
  filter(EVI_max <= 1 & EVI_min >= -1)
```

Split into training and test data sets.

```{r}
train_indices1 <- sample(1:nrow(filtered_data1), 0.7 * nrow(filtered_data1))
train_data1 <- filtered_data1[train_indices1, ]
test_data1 <- filtered_data1[-train_indices1, ]
```

Number of points per category for filtered data:

```{r}
filtered_data1 %>% count(EUNISa_1)
```

Investigate package ggparty (e.g. autoplot function, and more).

TO-DO: 
Choose the hyperparameter mtry based on the square root of the number of predictor variables (Hastie et al., 2009)-

Hastie, T., Tibshirani, R., & Friedman, J. (2009). The elements of statistical
learning: Data mining, inference, and prediction. Springer Science &
Business Media.

Maybe TO_DO:
We variated ntree from 50 to 800 in steps of 50, leaving mtry constant at 2. Tis parameter variation showed that ntree=500 was optimal, while higher ntree led to no further model improvement (Supplementary Fig. S10). Subsequently, the hyperparameter mtry was varied from 2 to 8 with constant ntree=500. Here, mtry=3 led to the best results in almost all cases (Supplementary Fig. S11). Consequently, we chose ntree=500 and mtry=3 for our main analysis across all study sites.

```{r}
rf_cforest1 <- party::cforest(EUNISa_1 ~ NDVI_max + NDVI_min + NDMI_max +
                                NDMI_min + NDWI_max + NDWI_min + EVI_max +
                                EVI_min + SAVI_max + SAVI_min + canopy_height, 
                              data = train_data1,
                              controls = cforest_control(
                                mtry = 3,
                                # mtry = sqrt(11)
                                # Default mtry = 5
                                # Bagging: mtry = NULL
                                # or = number of input variables
                                ntree = 500) # Default, try increasing
                              ) 
```

```{r}
predictions_rf_cforest1 <- predict(rf_cforest1, newdata = test_data1,
                                   OOB = TRUE, type = "response")
```

Confusion matrix:

```{r}
confusionMatrix(predictions_rf_cforest1, test_data1$EUNISa_1)
```

SurrogateTree --> does not work

```{r}
varimp_rf_cforest1 <- party::varimp(rf_cforest1, conditional = F) 
```

```{r eval=FALSE, include=FALSE}
varimp_rf_cond_cforest1 <- party::varimp(rf_cforest1, conditional = T)
# conditional = T adjusts for correlations between predictor variables
# Takes long!
save(varimp_rf_cond_cforest1, file = "objects/varimp_rf_cond_cforest1.Rdata")
```

Variable Importance Plot

```{r}
varimp_rf_cforest1_df <- data.frame(Variable = names(varimp_rf_cforest1),
                                    Importance = varimp_rf_cforest1)
ggplot(varimp_rf_cforest1_df,
       aes(x = reorder(Variable, Importance), y = Importance)) +
  geom_bar(stat = "identity", fill = "lightblue") +
  coord_flip() + theme_minimal() +
  labs(title = "Variable Importance", x = "Variables", y = "Importance")
```

Tree Visualization

```{r}
# Create a single conditional inference tree using ctree
single_tree1 <- ctree(EUNISa_1 ~ NDVI_max + NDVI_min + NDMI_max + NDMI_min +
                       NDWI_max + NDWI_min + EVI_max + EVI_min + SAVI_max +
                       SAVI_min + canopy_height,
                     data = train_data1)

# Plot the single tree using
autoplot(single_tree1)
```

ROC curves:

```{r}
# Predict probabilities for each class
probabilities <- predict(rf_cforest1, newdata = test_data1, type = "prob")

# Step 1: Convert list of matrices to a proper data frame
prob_matrix <- t(sapply(probabilities, as.vector))
colnames(prob_matrix) <- c("Q", "R", "S", "T")  # Adjust if needed
prob_df <- as.data.frame(prob_matrix)

# Step 2: Prepare actual class labels
actual <- factor(test_data1$EUNISa_1, levels = c("Q", "R", "S", "T"))
classes <- levels(actual)

# Step 3: Binarize actual labels
actual_bin <- model.matrix(~ actual - 1)
colnames(actual_bin) <- gsub("actual", "", colnames(actual_bin))

# Step 4: Compute ROC data for each class with AUC in label
roc_data <- lapply(classes, function(class) {
  roc_obj <- roc(actual_bin[, class], prob_df[[class]])
  auc_val <- round(auc(roc_obj), 3)
  data.frame(
    FPR = rev(roc_obj$specificities),
    TPR = rev(roc_obj$sensitivities),
    Class = paste0(class, " (AUC = ", auc_val, ")")
  )
}) %>% bind_rows()

# Step 5: Plot ROC curves with ggplot2
roc1 <- ggplot(roc_data, aes(x = FPR, y = TPR, color = Class)) +
  geom_line(size = 1.2) +
  geom_abline(linetype = "dashed", color = "gray") +
  labs(
    title = "Multiclass ROC Curves with AUC",
    x = "False Positive Rate",
    y = "True Positive Rate",
    color = "Class (AUC)"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")
roc1
```


## All GPS points within IQ range

Filter the data to get only GPS-points within IQ range of NDVI_max and NDMI_min.

```{r}
IQ_ranges <- all_GPS_valid %>%
  group_by(EUNISa_1) %>%
  summarize(
    Q1_NDVI_max = quantile(NDVI_max, 0.25, na.rm = T),
    Q1_NDMI_min = quantile(NDMI_min, 0.25, na.rm = T),
    Q3_NDVI_max = quantile(NDVI_max, 0.75, na.rm = T),
    Q3_NDMI_min = quantile(NDMI_min, 0.75, na.rm = T),
    IQR_NDVI_max = IQR(NDVI_max, na.rm = TRUE),
    IQR_NDMI_min = IQR(NDMI_min, na.rm = TRUE)
    )

# Join the IQ ranges back to the original data
all_GPS_valid <- all_GPS_valid %>%
  left_join(IQ_ranges, by = "EUNISa_1")

# Filter rows within the IQR range for both variables
filtered_data2 <- all_GPS_valid %>%
  filter(
    (NDVI_max >= Q1_NDVI_max & NDVI_max <= Q3_NDVI_max) &
    (NDMI_min >= Q1_NDMI_min & NDMI_min <= Q3_NDMI_min)
    ) %>%
  filter(!is.na(NDVI_max) & !is.na(NDMI_max) & !is.na(NDWI_max) &
           !is.na(SAVI_max) & !is.na(EVI_max) & !is.na(NDVI_min) &
           !is.na(NDMI_min) & !is.na(NDWI_min) & !is.na(SAVI_min) &
           !is.na(EVI_min)) %>%
  mutate(EUNISa_1 = as.factor(EUNISa_1)) %>%
  filter(EVI_max <= 1 & EVI_min >= -1)
```

Split into training and test data sets.

```{r}
train_indices2 <- sample(1:nrow(filtered_data2), 0.7 * nrow(filtered_data2))
train_data2 <- filtered_data2[train_indices2, ]
test_data2 <- filtered_data2[-train_indices2, ]
```

Number of points per category for filtered data:

```{r}
filtered_data2 %>% count(EUNISa_1)
```

```{r}
rf_cforest2 <- party::cforest(EUNISa_1 ~ NDVI_max + NDVI_min + NDMI_max +
                                NDMI_min + NDWI_max + NDWI_min + EVI_max +
                                EVI_min + SAVI_max + SAVI_min + canopy_height, 
                              data = train_data2,
                              controls = cforest_control(
                                mtry = 3,
                                # mtry = sqrt(11)
                                # Default mtry = 5
                                # Bagging: mtry = NULL
                                # or = number of input variables
                                ntree = 500) # Default, try increasing
                              ) 
```

```{r}
predictions_rf_cforest2 <- predict(rf_cforest2, newdata = test_data2,
                                   OOB = TRUE, type = "response")
```

Confusion matrix:

```{r}
confusionMatrix(predictions_rf_cforest2, test_data2$EUNISa_1)
```

```{r}
varimp_rf_cforest2 <- party::varimp(rf_cforest2, conditional = F) 
```

```{r eval=FALSE, include=FALSE}
varimp_rf_cond_cforest2 <- party::varimp(rf_cforest2, conditional = T)
# conditional = T adjusts for correlations between predictor variables
# Takes long!
save(varimp_rf_cond_cforest2, file = "objects/varimp_rf_cond_cforest2.Rdata")
```

Variable Importance Plot

```{r}
varimp_rf_cforest2_df <- data.frame(Variable = names(varimp_rf_cforest2),
                                    Importance = varimp_rf_cforest2)
ggplot(varimp_rf_cforest2_df,
       aes(x = reorder(Variable, Importance), y = Importance)) +
  geom_bar(stat = "identity", fill = "lightblue") +
  coord_flip() + theme_minimal() +
  labs(title = "Variable Importance", x = "Variables", y = "Importance")
```

ROC curves:

```{r}
# Predict probabilities for each class
probabilities <- predict(rf_cforest1, newdata = test_data1, type = "prob")

# Step 1: Convert list of matrices to a proper data frame
prob_matrix <- t(sapply(probabilities, as.vector))
colnames(prob_matrix) <- c("Q", "R", "S", "T")  # Adjust if needed
prob_df <- as.data.frame(prob_matrix)

# Step 2: Prepare actual class labels
actual <- factor(test_data1$EUNISa_1, levels = c("Q", "R", "S", "T"))
classes <- levels(actual)

# Step 3: Binarize actual labels
actual_bin <- model.matrix(~ actual - 1)
colnames(actual_bin) <- gsub("actual", "", colnames(actual_bin))

# Step 4: Compute ROC data for each class with AUC in label
roc_data <- lapply(classes, function(class) {
  roc_obj <- roc(actual_bin[, class], prob_df[[class]])
  auc_val <- round(auc(roc_obj), 3)
  data.frame(
    FPR = rev(roc_obj$specificities),
    TPR = rev(roc_obj$sensitivities),
    Class = paste0(class, " (AUC = ", auc_val, ")")
  )
}) %>% bind_rows()

# Step 5: Plot ROC curves with ggplot2
roc2 <- ggplot(roc_data, aes(x = FPR, y = TPR, color = Class)) +
  geom_line(size = 1.2) +
  geom_abline(linetype = "dashed", color = "gray") +
  labs(
    title = "Multiclass ROC Curves with AUC",
    x = "False Positive Rate",
    y = "True Positive Rate",
    color = "Class (AUC)"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")
roc2
```

## All GPS points within 1.5 * IQ range

Filter the data to get only GPS-points within 1.5 * IQ range of NDVI_max and NDMI_min.

```{r}
# Filter rows within the 1.5 * IQR range for both variables
filtered_data3 <- all_GPS_valid %>%
  filter(
    (NDVI_max >= (Q1_NDVI_max - 1.5 * IQR_NDVI_max) & NDVI_max <= (Q3_NDVI_max + 1.5 * IQR_NDVI_max)) &
      (NDMI_min >= (Q1_NDMI_min - 1.5 * IQR_NDMI_min) & NDMI_min <= (Q3_NDMI_min + 1.5 * IQR_NDMI_min))
    ) %>%
  filter(!is.na(NDVI_max) & !is.na(NDMI_max) & !is.na(NDWI_max) &
           !is.na(SAVI_max) & !is.na(EVI_max) & !is.na(NDVI_min) &
           !is.na(NDMI_min) & !is.na(NDWI_min) & !is.na(SAVI_min) &
           !is.na(EVI_min)) %>%
  mutate(EUNISa_1 = as.factor(EUNISa_1)) %>%
  filter(EVI_max <= 1 & EVI_min >= -1)
```

Split into training and test data sets.

```{r}
train_indices3 <- sample(1:nrow(filtered_data3), 0.7 * nrow(filtered_data3))
train_data3 <- filtered_data3[train_indices3, ]
test_data3 <- filtered_data3[-train_indices3, ]
```

Number of points per category for filtered data:

```{r}
filtered_data3 %>% count(EUNISa_1)
```

```{r}
rf_cforest3 <- party::cforest(EUNISa_1 ~ NDVI_max + NDVI_min + NDMI_max +
                                NDMI_min + NDWI_max + NDWI_min + EVI_max +
                                EVI_min + SAVI_max + SAVI_min + canopy_height, 
                              data = train_data3,
                              controls = cforest_control(
                                mtry = 3,
                                # mtry = sqrt(11)
                                # Default mtry = 5
                                # Bagging: mtry = NULL
                                # or = number of input variables
                                ntree = 500) # Default, try increasing
                              ) 
```

```{r}
predictions_rf_cforest3 <- predict(rf_cforest3, newdata = test_data3,
                                   OOB = TRUE, type = "response")
```

Confusion matrix:

```{r}
confusionMatrix(predictions_rf_cforest3, test_data3$EUNISa_1)
```

```{r}
varimp_rf_cforest3 <- party::varimp(rf_cforest3, conditional = F) 
```

```{r eval=FALSE, include=FALSE}
varimp_rf_cond_cforest3 <- party::varimp(rf_cforest3, conditional = T)
# conditional = T adjusts for correlations between predictor variables
# Takes long!
save(varimp_rf_cond_cforest3, file = "objects/varimp_rf_cond_cforest3.Rdata")
```

Variable Importance Plot

```{r}
varimp_rf_cforest3_df <- data.frame(Variable = names(varimp_rf_cforest3),
                                    Importance = varimp_rf_cforest3)
ggplot(varimp_rf_cforest3_df,
       aes(x = reorder(Variable, Importance), y = Importance)) +
  geom_bar(stat = "identity", fill = "lightblue") +
  coord_flip() + theme_minimal() +
  labs(title = "Variable Importance", x = "Variables", y = "Importance")
```

ROC curves:

```{r}
# Predict probabilities for each class
probabilities <- predict(rf_cforest1, newdata = test_data1, type = "prob")

# Step 1: Convert list of matrices to a proper data frame
prob_matrix <- t(sapply(probabilities, as.vector))
colnames(prob_matrix) <- c("Q", "R", "S", "T")  # Adjust if needed
prob_df <- as.data.frame(prob_matrix)

# Step 2: Prepare actual class labels
actual <- factor(test_data1$EUNISa_1, levels = c("Q", "R", "S", "T"))
classes <- levels(actual)

# Step 3: Binarize actual labels
actual_bin <- model.matrix(~ actual - 1)
colnames(actual_bin) <- gsub("actual", "", colnames(actual_bin))

# Step 4: Compute ROC data for each class with AUC in label
roc_data <- lapply(classes, function(class) {
  roc_obj <- roc(actual_bin[, class], prob_df[[class]])
  auc_val <- round(auc(roc_obj), 3)
  data.frame(
    FPR = rev(roc_obj$specificities),
    TPR = rev(roc_obj$sensitivities),
    Class = paste0(class, " (AUC = ", auc_val, ")")
  )
}) %>% bind_rows()

# Step 5: Plot ROC curves with ggplot2
roc3 <- ggplot(roc_data, aes(x = FPR, y = TPR, color = Class)) +
  geom_line(size = 1.2) +
  geom_abline(linetype = "dashed", color = "gray") +
  labs(
    title = "Multiclass ROC Curves with AUC",
    x = "False Positive Rate",
    y = "True Positive Rate",
    color = "Class (AUC)"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")
roc3
```

## All GPS points within mean +/- SD

Filter the data to get only GPS-points within mean +/- SD of NDVI_max and NDMI_min.

```{r}
mean_sd <- all_GPS_valid %>%
  group_by(EUNISa_1) %>%
  summarize(
    mean_NDVI_max = mean(all_GPS_valid$NDVI_max, na.rm = T),
    mean_NDMI_min = mean(all_GPS_valid$NDMI_min, na.rm = T),
    sd_NDVI_max = sd(all_GPS_valid$NDVI_max, na.rm = T),
    sd_NDMI_min = sd(all_GPS_valid$NDMI_min, na.rm = T)
    )

# Join the IQ ranges back to the original data
all_GPS_valid <- all_GPS_valid %>%
  left_join(mean_sd, by = "EUNISa_1")

# Filter rows within the specified range for both variables
filtered_data4 <- all_GPS_valid %>%
  filter(
    (NDVI_max >= (mean_NDVI_max - sd_NDVI_max) & NDVI_max <= (mean_NDVI_max + sd_NDVI_max)) &
      (NDMI_min >= (mean_NDMI_min - sd_NDMI_min) & NDMI_min <= (mean_NDMI_min + sd_NDMI_min))
    ) %>%
  filter(!is.na(NDVI_max) & !is.na(NDMI_max) & !is.na(NDWI_max) &
           !is.na(SAVI_max) & !is.na(EVI_max) & !is.na(NDVI_min) &
           !is.na(NDMI_min) & !is.na(NDWI_min) & !is.na(SAVI_min) &
           !is.na(EVI_min)) %>%
  mutate(EUNISa_1 = as.factor(EUNISa_1)) %>%
  filter(EVI_max <= 1 & EVI_min >= -1)
```

Split into training and test data sets.

```{r}
train_indices4 <- sample(1:nrow(filtered_data4), 0.7 * nrow(filtered_data4))
train_data4 <- filtered_data4[train_indices4, ]
test_data4 <- filtered_data4[-train_indices4, ]
```

Number of points per category for filtered data:

```{r}
filtered_data4 %>% count(EUNISa_1)
```

```{r}
rf_cforest4 <- party::cforest(EUNISa_1 ~ NDVI_max + NDVI_min + NDMI_max +
                                NDMI_min + NDWI_max + NDWI_min + EVI_max +
                                EVI_min + SAVI_max + SAVI_min + canopy_height, 
                              data = train_data4,
                              controls = cforest_control(
                                mtry = 3,
                                # mtry = sqrt(11)
                                # Default mtry = 5
                                # Bagging: mtry = NULL
                                # or = number of input variables
                                ntree = 500) # Default, try increasing
                              ) 
```

```{r}
predictions_rf_cforest4 <- predict(rf_cforest4, newdata = test_data4,
                                   OOB = TRUE, type = "response")
```

Confusion matrix:

```{r}
confusionMatrix(predictions_rf_cforest4, test_data4$EUNISa_1)
```

```{r}
varimp_rf_cforest4 <- party::varimp(rf_cforest4, conditional = F) 
```

```{r eval=FALSE, include=FALSE}
varimp_rf_cond_cforest4 <- party::varimp(rf_cforest4, conditional = T)
# conditional = T adjusts for correlations between predictor variables
# Takes long!
save(varimp_rf_cond_cforest4, file = "objects/varimp_rf_cond_cforest4.Rdata")
```

Variable Importance Plot

```{r}
varimp_rf_cforest4_df <- data.frame(Variable = names(varimp_rf_cforest4),
                                    Importance = varimp_rf_cforest4)
ggplot(varimp_rf_cforest4_df,
       aes(x = reorder(Variable, Importance), y = Importance)) +
  geom_bar(stat = "identity", fill = "lightblue") +
  coord_flip() + theme_minimal() +
  labs(title = "Variable Importance", x = "Variables", y = "Importance")
```

ROC curves:

```{r}
# Predict probabilities for each class
probabilities <- predict(rf_cforest1, newdata = test_data1, type = "prob")

# Step 1: Convert list of matrices to a proper data frame
prob_matrix <- t(sapply(probabilities, as.vector))
colnames(prob_matrix) <- c("Q", "R", "S", "T")  # Adjust if needed
prob_df <- as.data.frame(prob_matrix)

# Step 2: Prepare actual class labels
actual <- factor(test_data1$EUNISa_1, levels = c("Q", "R", "S", "T"))
classes <- levels(actual)

# Step 3: Binarize actual labels
actual_bin <- model.matrix(~ actual - 1)
colnames(actual_bin) <- gsub("actual", "", colnames(actual_bin))

# Step 4: Compute ROC data for each class with AUC in label
roc_data <- lapply(classes, function(class) {
  roc_obj <- roc(actual_bin[, class], prob_df[[class]])
  auc_val <- round(auc(roc_obj), 3)
  data.frame(
    FPR = rev(roc_obj$specificities),
    TPR = rev(roc_obj$sensitivities),
    Class = paste0(class, " (AUC = ", auc_val, ")")
  )
}) %>% bind_rows()

# Step 5: Plot ROC curves with ggplot2
roc4 <- ggplot(roc_data, aes(x = FPR, y = TPR, color = Class)) +
  geom_line(size = 1.2) +
  geom_abline(linetype = "dashed", color = "gray") +
  labs(
    title = "Multiclass ROC Curves with AUC",
    x = "False Positive Rate",
    y = "True Positive Rate",
    color = "Class (AUC)"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")
roc4
```

## All GPS points above p20 and below p80

Filter the data to get only GPS-points above p20 and below p80 of NDVI_max and NDMI_min.

```{r}
# Filter rows above the 20th percentile and below the 80th percentile for both variables
filtered_data5 <- all_GPS_valid %>%
  filter(
    (NDVI_max >= percentile_20_NDVI_max & NDVI_max <= percentile_80_NDVI_max) &
    (NDMI_min >= percentile_20_NDMI_min & NDMI_min <= percentile_80_NDMI_min)
    ) %>%
  filter(!is.na(NDVI_max) & !is.na(NDMI_max) & !is.na(NDWI_max) &
           !is.na(SAVI_max) & !is.na(EVI_max) & !is.na(NDVI_min) &
           !is.na(NDMI_min) & !is.na(NDWI_min) & !is.na(SAVI_min) &
           !is.na(EVI_min)) %>%
  mutate(EUNISa_1 = as.factor(EUNISa_1)) %>%
  filter(EVI_max <= 1 & EVI_min >= -1)
```

Split into training and test data sets.

```{r}
train_indices5 <- sample(1:nrow(filtered_data5), 0.7 * nrow(filtered_data5))
train_data5 <- filtered_data5[train_indices5, ]
test_data5 <- filtered_data5[-train_indices5, ]
```

Number of points per category for filtered data:

```{r}
filtered_data5 %>% count(EUNISa_1)
```

```{r}
rf_cforest5 <- party::cforest(EUNISa_1 ~ NDVI_max + NDVI_min + NDMI_max +
                                NDMI_min + NDWI_max + NDWI_min + EVI_max +
                                EVI_min + SAVI_max + SAVI_min + canopy_height, 
                              data = train_data5,
                              controls = cforest_control(
                                mtry = 3,
                                # mtry = sqrt(11)
                                # Default mtry = 5
                                # Bagging: mtry = NULL
                                # or = number of input variables
                                ntree = 500) # Default, try increasing
                              ) 
```

```{r}
predictions_rf_cforest5 <- predict(rf_cforest5, newdata = test_data5,
                                   OOB = TRUE, type = "response")
```

Confusion matrix:

```{r}
confusionMatrix(predictions_rf_cforest5, test_data5$EUNISa_1)
```

```{r}
varimp_rf_cforest5 <- party::varimp(rf_cforest5, conditional = F) 
```

```{r eval=FALSE, include=FALSE}
varimp_rf_cond_cforest5 <- party::varimp(rf_cforest5, conditional = T)
# conditional = T adjusts for correlations between predictor variables
# Takes long!
save(varimp_rf_cond_cforest5, file = "objects/varimp_rf_cond_cforest5.Rdata")
```

Variable Importance Plot

```{r}
varimp_rf_cforest5_df <- data.frame(Variable = names(varimp_rf_cforest5),
                                    Importance = varimp_rf_cforest5)
ggplot(varimp_rf_cforest5_df,
       aes(x = reorder(Variable, Importance), y = Importance)) +
  geom_bar(stat = "identity", fill = "lightblue") +
  coord_flip() + theme_minimal() +
  labs(title = "Variable Importance", x = "Variables", y = "Importance")
```

ROC curves:

```{r}
# Predict probabilities for each class
probabilities <- predict(rf_cforest1, newdata = test_data1, type = "prob")

# Step 1: Convert list of matrices to a proper data frame
prob_matrix <- t(sapply(probabilities, as.vector))
colnames(prob_matrix) <- c("Q", "R", "S", "T")  # Adjust if needed
prob_df <- as.data.frame(prob_matrix)

# Step 2: Prepare actual class labels
actual <- factor(test_data1$EUNISa_1, levels = c("Q", "R", "S", "T"))
classes <- levels(actual)

# Step 3: Binarize actual labels
actual_bin <- model.matrix(~ actual - 1)
colnames(actual_bin) <- gsub("actual", "", colnames(actual_bin))

# Step 4: Compute ROC data for each class with AUC in label
roc_data <- lapply(classes, function(class) {
  roc_obj <- roc(actual_bin[, class], prob_df[[class]])
  auc_val <- round(auc(roc_obj), 3)
  data.frame(
    FPR = rev(roc_obj$specificities),
    TPR = rev(roc_obj$sensitivities),
    Class = paste0(class, " (AUC = ", auc_val, ")")
  )
}) %>% bind_rows()

# Step 5: Plot ROC curves with ggplot2
roc5 <- ggplot(roc_data, aes(x = FPR, y = TPR, color = Class)) +
  geom_line(size = 1.2) +
  geom_abline(linetype = "dashed", color = "gray") +
  labs(
    title = "Multiclass ROC Curves with AUC",
    x = "False Positive Rate",
    y = "True Positive Rate",
    color = "Class (AUC)"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")
roc5
```

# HERE: Compare RF 1-5

# Cordillera data

```{r}
AlpineGrasslands_indices <- read_csv(
  "C:/Data/MOTIVATE/Cordillera/AlpineGrasslands/AlpineGrassland_Sentinel_Plot_Allyear_Allmetrics.csv")
AlpineGrasslands_phen <- read_csv(
  "C:/Data/MOTIVATE/Cordillera/AlpineGrasslands/AlpineGrasslands_Phenology_SOS_EOS_Peak_NDVI_Amplitude.csv")
AlpineGrasslands_CH <- read_csv(
  "C:/Data/MOTIVATE/Cordillera/AlpineGrasslands/AlpineGrasslands_CanopyHeight_1m.csv")
VegetationTypes_indices <- read_csv(
  "C:/Data/MOTIVATE/Cordillera/VegetationTypes/VegetationTypes_Sentinel_Plot_AllYear_Allmetrics.csv")
VegetationTypes_phen <- read_csv(
  "C:/Data/MOTIVATE/Cordillera/VegetationTypes/VegetationTypes_Phenology_SOS_EOS_Peak_NDVI_Amplitude.csv")
VegetationTypes_CH <- read_csv(
  "C:/Data/MOTIVATE/Cordillera/VegetationTypes/VegetationTypes_CanopyHeight_1m.csv")
```

```{r}
AlpineGrasslands <- AlpineGrasslands_indices %>%
  select(-`system:index`, -.geo, -Localidad) %>%
  rename(H√°bitat = "HÔøΩbitat") %>% 
  full_join(AlpineGrasslands_phen  %>%
              select(-`system:index`, -.geo, -Localidad) %>%
              rename(H√°bitat = "HÔøΩbitat")) %>%
  full_join(AlpineGrasslands_CH  %>%
              select(-`system:index`, -.geo, -Localidad)) %>%
  select(-Date__year, - `PrecisiÔøΩn`) %>%
  mutate(DATE = ymd(DATE)) %>%
  rename(ID = "Releve_num") %>%
  mutate(ID = as.character(ID)) %>%
  mutate(layer = "AlpineGrasslands")
```

```{r}
VegetationTypes <- VegetationTypes_indices %>%
  select(-`system:index`, -.geo) %>%
  full_join(VegetationTypes_phen  %>%
              select(-`system:index`, -.geo)) %>%
  full_join(VegetationTypes_CH  %>%
              select(-`system:index`, -.geo)) %>%
  rename(H√°bitat = "TYPE") %>%
  mutate(layer = "VegetationTypes")
```

Merge both datasets:

```{r}
cordillera <- bind_rows(
  AlpineGrasslands %>% select(DATE, ID, starts_with("NDMI"),
                              starts_with("NDVI"), H√°bitat, "EOS_DOY",
                              "Peak_DOY", "SOS_DOY", "Season_Length",
                              "canopy_height", "layer"),
  VegetationTypes %>% select(DATE, ID, starts_with("NDMI"),
                              starts_with("NDVI"), H√°bitat, "EOS_DOY",
                              "Peak_DOY", "SOS_DOY", "Season_Length",
                              "canopy_height", "layer")
  ) %>%
  mutate(EUNISa_1 = case_when(
    H√°bitat = str_detect(H√°bitat, "Pastizal|Cervunal|grassland|meadow") ~ "R",
    H√°bitat = str_detect(H√°bitat, "forest") ~ "T",
    H√°bitat = str_detect(H√°bitat, "Scrub|scrub|Shrubland|shrubland|shrub|Heathland") ~ "S",
    H√°bitat = str_detect(H√°bitat, "Suelo|Scree|scree|cliff") ~ "U",
    H√°bitat = is.na(H√°bitat) ~ "R",
    TRUE ~ NA_character_),
    EUNISa_1_descr = case_when(
      EUNISa_1 == "R" ~ "Grasslands",
      EUNISa_1 == "T" ~ "Forests and other wooded land",
      EUNISa_1 == "S" ~ "Heathlands, scrub and tundra",
      EUNISa_1 == "U" ~ "Inland habitats with no or little soil")
    )
```

## NDVI, NDMI

```{r}
distr_plot(cordillera,
           c("NDVI_max", "NDVI_p90", "NDVI_min", "NDVI_p10"), 
           c("NDVI max", "NDVI p90", "NDVI min", "NDVI p10"))
distr_plot(cordillera,
           c("NDMI_max", "NDMI_p90", "NDMI_min", "NDMI_p10"), 
           c("NDMI max", "NDMI p90", "NDMI min", "NDMI p10"))
```

# Session info

```{r}
sessionInfo()
```

