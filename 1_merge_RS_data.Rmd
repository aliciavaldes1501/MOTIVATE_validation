---
title: "Script to merge all RS data"
author: "Alicia Vald√©s"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: html_notebook
---

This R script is used to merge RS data downloaded the Google Drive folder shared by Bea with the ReSurvey database.

# Load libraries

```{r}
library(tidyverse)
library(here)
library(lubridate)
library(dtplyr)
library(sf)
```

# Read files with RS data from Bea

## S2 

### NDVI, NDMI & other indices

Files downloaded from folder Drive/MOTIVATE-EVEREST/1.VALIDATION/db_Europe/S2/Ene-dic

```{r}
# Set the folder path
folder_path <- "C:/Data/MOTIVATE/MOTIVATE_RS_data/S2"

# List CSV files
csv_files <- list.files(folder_path, full.names = TRUE, recursive = TRUE)

# Function to extract biogeo and unit from the filename
extract_info <- function(filename) {
  first_word <- strsplit(filename, "_")[[1]][1]
  biogeo <- str_extract(first_word, "^(ALP|ARC|ATL|BOR|CON|MED|PANONIA)")
  unit <- str_remove(first_word, biogeo)
  if (unit == "") unit <- NA_character_
  list(biogeo = biogeo, unit = unit)
}


# Read and process each file
data_list <- lapply(csv_files, function(file) {
  info <- extract_info(basename(file)) # Use only the filename
  
  # Read the file
  df <- read_csv(file) %>%
    # Remove columns that give column type problems when combining data
    select(-starts_with("EUNIS"), -starts_with("ReSurvey")) %>%
    mutate(biogeo = info$biogeo, unit = info$unit)
  
  return(df)
  })

# Combine all data
data_RS_S2 <- bind_rows(data_list)

# View the resulting tibble
print(data_RS_S2)

# Counts per biogeo and unit
print(data_RS_S2 %>% count(biogeo, unit), n = 100)
```

#### Data cleaning

Keep all indices and metrics in case they are useful.

```{r}
data_RS_S2 <- data_RS_S2 %>%
  # Keep the columns we need
  select(PlotObserv, biogeo, unit, year, Lat_update, Lon_update,
         starts_with("NDVI"), starts_with("NDMI"), starts_with("NDWI"),
         starts_with("EVI"), starts_with("SAVI")) %>%
  # Rename Lat and Lon, these are only kept in case there is difference with
  # those in the ReSurvey database due to updates based on Ilona's info
  rename(Lat_RS = Lat_update, Lon_RS = Lon_update) %>%
  # Same for year
  rename(year_RS = year) %>%
  # Add column source
  mutate(source = "S2")
```

### Phenology S2

#### HERE: Do not use so far - wrong!

<!-- Manually renamed all files as REGION_SUBREGION_Phenology. -->

<!-- ```{r} -->
<!-- # Set the folder path -->
<!-- folder_path <- "C:/Data/MOTIVATE/MOTIVATE_RS_data/S2" -->

<!-- # List only CSV files that contain "Phenology" in their filename -->
<!-- csv_files <- list.files(folder_path, pattern = "Phenology.*\\.csv$", -->
<!--                         full.names = TRUE, recursive = TRUE) -->

<!-- # Function to read each file and extract info from the filename -->
<!-- read_and_label <- function(file_path) { -->
<!--   file_name <- basename(file_path) -->

<!--   # Extract region and subregion from the filename -->
<!--   # Updated regular expression to handle the case where subregion is missing -->
<!--   components <- str_match(file_name, -->
<!--                           "^[0-9_]*([^_]+)_([^_]+)_Phenology.csv") -->

<!--   # Extract the biogeo and unit, handling missing subregion (unit) -->
<!--   biogeo <- components[2] -->

<!--   # If subregion (unit) is missing, set it as NA -->
<!--   unit <- ifelse(is.na(components[3]), NA, components[3]) -->

<!--   # Check if biogeo is missing, and if so, -->
<!--   # assign the first part of the filename (region name) -->
<!--   if (is.na(biogeo) && grepl("_Phenology", file_name)) { -->
<!--     # Capture the first part (biogeo) directly -->
<!--     biogeo <- str_match(file_name, "^[0-9_]*([^_]+)_Phenology")[2] -->
<!--   } -->

<!--   # If biogeo is still NA, print a warning -->
<!--   if (is.na(biogeo)) { -->
<!--     warning(paste("Failed to extract biogeo for file:", file_name)) -->
<!--   } -->

<!--   # Read CSV and add columns for extracted info -->
<!--   read_csv(file_path) %>% -->
<!--     mutate(biogeo = biogeo, unit = unit) -->
<!-- } -->
<!-- # Read and merge all CSV files -->
<!-- data_RS_S2_phen <- map_dfr(csv_files, read_and_label) -->

<!-- # View the resulting tibble -->
<!-- print(data_RS_S2_phen) -->

<!-- # Counts per biogeo and unit -->
<!-- print(data_RS_S2_phen %>% count(biogeo, unit), n = 100) -->
<!-- ``` -->

<!-- #### Data cleaning -->

<!-- ```{r} -->
<!-- data_RS_S2_phen <- data_RS_S2_phen %>% -->
<!--   # Keep the columns we need: -->
<!--   # Dates were wrongly exported from GEE - removed them and recalculated later. -->
<!--   # Remove Lat and Lon and year, in case there is difference with -->
<!--   # those in the ReSurvey database due to updates based on Ilona's info, -->
<!--   # we have Lat_RS, Lon_RS and year_RS from data_RS_S2 -->
<!--   select(obs_unique, biogeo, unit, SOS_DOY, NDVI_at_SOS, Peak_DOY, NDVI_at_Peak, -->
<!--          EOS_DOY, NDVI_at_EOS, Season_Length, year) %>% -->
<!--   # make_date() creates a date at the start of the year (January 1st).  -->
<!--   # By adding days(DOY - 1), we correctly position the date within the year. -->
<!--   mutate(SOS_date = make_date(year) + days(SOS_DOY - 1), -->
<!--          Peak_date = make_date(year) + days(Peak_DOY - 1), -->
<!--          EOS_date = make_date(year) + days(EOS_DOY - 1)) %>% -->
<!--   # Remove year -->
<!--   select(-year) -->
<!-- ``` -->

## Landsat

### NDVI, NDMI & other indices

```{r}
# Set the folder path
folder_path <- "C:/Data/MOTIVATE/MOTIVATE_RS_data/Landsat"

# List CSV files
csv_files <- list.files(folder_path, full.names = TRUE, recursive = TRUE)

# Function to extract biogeo and unit from the filename
extract_info <- function(filename) {
  first_word <- strsplit(filename, "_")[[1]][1]
  biogeo <- str_extract(first_word, "^(ALP|ARC|ATL|BOR|CON|MED|PANONIA)")
  unit <- str_remove(first_word, biogeo)
  if (unit == "") unit <- NA_character_
  list(biogeo = biogeo, unit = unit)
}

# Read and process each file
data_list <- lapply(csv_files, function(file) {
  info <- extract_info(basename(file)) # Use only the filename
  
  # Read the file
  df <- read_csv(file) %>%
    # Remove columns that give column type problems when combining data
    select(-starts_with("EUNIS"), -starts_with("ReSurvey")) %>%
    mutate(biogeo = info$biogeo, unit = info$unit)
  
  return(df)
  })

# Combine all data
data_RS_Landsat <- bind_rows(data_list)

# View the resulting tibble
print(data_RS_Landsat)

# Counts per biogeo and unit
print(data_RS_Landsat %>% count(biogeo, unit), n = 100)
```

#### Data cleaning

Keep all indices and metrics in case they are useful.

```{r}
data_RS_Landsat <- data_RS_Landsat %>%
  # Keep the columns we need
  select(PlotObserv, biogeo, unit, year, Lat_update, Lon_update,
         starts_with("NDVI"), starts_with("NDMI"), starts_with("NDWI"),
         starts_with("EVI"), starts_with("SAVI")) %>%
  # Rename Lat and Lon, these are only kept in case there is difference with
  # those in the ReSurvey database due to updates based on Ilona's info
  rename(Lat_RS = Lat_update, Lon_RS = Lon_update) %>%
  # Same for year
  rename(year_RS = year) %>%
  # Add column source
  mutate(source = "Landsat")
```

### TO ADD: Phenology Landsat

## Canopy height

```{r}
data_RS_CH <- read_csv(
  "C:/Data/MOTIVATE/MOTIVATE_RS_data/Canopy_Height_1m/Europe_points_CanopyHeight_1m.csv")
data_RS_CH
```

### Data cleaning CH

```{r}
data_RS_CH <- data_RS_CH %>%
  # Keep the columns we need
  select(obs_unique, canopy_height)
```

## TBD: Biomass

# Read file db_Europa

In this file, there is the correspondence obs_unique - PlotObservationID.

```{r}
db_Europa <- read_csv(
  here("..", "DB_first_check", "data", "clean","db_Europa_20250107.csv")
  )
```

# Sample db_Europa

## Read file db_resurv_updated_clean

This is the ReSurvey database after updates (to be continued).

```{r}
db_resurv <- read_tsv(
  here("..", "DB_first_check","data", "clean","db_resurv_updated_clean.csv"),
  col_types = cols(
    # Dynamically specify EUNIS columns as character
    .default = col_guess(),  # Default guessing for other columns
    EUNISa = col_character(),
    EUNISb = col_character(),
    EUNISc = col_character(),
    EUNISd = col_character(),
    EUNISa_1 = col_character(),
    EUNISa_2 = col_character(),
    EUNISa_3 = col_character(),
    EUNISa_4 = col_character(),
    EUNISb_1 = col_character(),
    EUNISb_2 = col_character(),
    EUNISb_3 = col_character(),
    EUNISb_4 = col_character(),
    EUNISc_1 = col_character(),
    EUNISc_2 = col_character(),
    EUNISc_3 = col_character(),
    EUNISc_4 = col_character(),
    EUNISd_1 = col_character(),
    EUNISd_2 = col_character(),
    EUNISd_3 = col_character(),
    EUNISd_4 = col_character(),
    EUNISa_1_descr = col_character(),
    EUNISb_1_descr = col_character(),
    EUNISc_1_descr = col_character(),
    EUNISd_1_descr = col_character(),
    EUNIS_assignation = col_character(),
    EUNISa_2_descr = col_character(),
    EUNISa_3_descr = col_character(),
    EUNISa_4_descr = col_character(),
    EUNISb_2_descr = col_character(),
    EUNISb_3_descr = col_character(),
    EUNISb_4_descr = col_character(),
    EUNISc_2_descr = col_character(),
    EUNISc_3_descr = col_character(),
    EUNISc_4_descr = col_character(),
    EUNISd_2_descr = col_character(),
    EUNISd_3_descr = col_character(),
    EUNISd_4_descr = col_character()
    )
  )
```

No parsing issues!

Get sample of ReSurvey database:

```{r}
db_Europa_sample <- left_join(
  db_resurv %>%
    select(PlotObservationID, RS_CODE, `ReSurvey site`, `ReSurvey plot`,
           Lon_updated,Lat_updated, year,date,
           starts_with("EUNIS"), `Location method`) %>%
    select(-EUNIS_assignation),
  db_Europa %>%
    select(PlotObservationID, Lon_updated, Lat_updated, year, obs_unique_id)
)
  
print(db_Europa_sample, width = Inf)
```

Add column PLOT to data to identify unique plots:

```{r}
db_Europa_sample <- db_Europa_sample %>%
  # Original names give problems, create new vars
  mutate(RS_site = `ReSurvey site`, RS_plot = `ReSurvey plot`) %>%
  # Convert to data.table for faster processing
  lazy_dt() %>%
  # Group by the 3 vars that uniquely identify each plot
  group_by(RS_CODE, RS_site, RS_plot) %>%
  # Create a new variable PLOT for each group
  mutate(PLOT = .GRP) %>%
  # Convert back to tibble
  as_tibble() %>%
  # Remove unneeded vars
  select(-RS_site, -RS_plot)
```

Keep only habitats F, R, S and Q, and, for each PLOT, keep only the last resurvey:

```{r}
db_Europa_sample_latest <- db_Europa_sample %>%
  filter(EUNISa_1 %in% c("T", "R", "S", "Q")) %>%
  group_by(PLOT) %>%
  filter(date == max(date)) %>%
  ungroup()
```

Save as csv for Bea:

```{r}
write_csv(db_Europa_sample_latest,
          file = "data/clean/db_Europa_sample_latest.csv")
```

Save as shp to merge with bioregions:

```{r}
# # Convert to sf object
# db_Europa_sample_latest_sf <- st_as_sf(db_Europa_sample_latest,
#                                        coords = c("Lon_updated", "Lat_updated"), 
#                                        crs = 4326) # WGS84
# st_write(db_Europa_sample_latest_sf,
#          "C:/GIS/MOTIVATE/shapefiles/db_Europa_sample_latest_sf.shp")
```

# Merge RS data and db_Europa_sample_latest

Get only the columns PlotObservationID (original unique identifier) and obs_unique_id (unique identified created by me).

```{r}
db_Europa_sample_latest <- db_Europa_sample_latest %>%
  select(PlotObservationID, obs_unique_id)
```

```{r}
data_RS_S2_ID <- db_Europa_sample_latest %>%
  right_join(data_RS_S2 %>%
               # Rename to be able to join on this column
               rename(PlotObservationID = PlotObserv))
```

Now we have PlotObservationID in data_RS_S2_ID.

```{r}
# data_RS_S2_phen_ID <- db_Europa_sample_latest %>%
#   right_join(data_RS_S2_phen %>%
#               # Rename to be able to join on this column
#                rename(PlotObservationID = PlotObserv))
```

Now we have PlotObservationID in data_RS_S2_phen_ID

```{r}
data_RS_Landsat_ID <- db_Europa_sample_latest %>%
  right_join(data_RS_Landsat %>%
               # Rename to be able to join on this column
               rename(PlotObservationID = PlotObserv))
```

Now we have PlotObservationID in data_RS_Landsat_ID.

```{r}
data_RS_CH_ID <- db_Europa %>%
  select(PlotObservationID, obs_unique_id) %>%
  right_join(data_RS_CH %>%
              # Rename to be able to join on this column
              rename(obs_unique_id = obs_unique))
```

Now we have PlotObservationID in data_RS_CH_ID.

# Merge RS data to the ReSurvey database

For some points, there is data both from S2 and Landsat. In those cases, use the S2 data because it is more precise (10 m vs 30 m).

```{r}
data_RS_S2_ID <- data_RS_S2_ID %>%
  rename_with(~ paste0(., "_S2"), starts_with("NDVI")) %>%
  rename_with(~ paste0(., "_S2"), starts_with("NDMI")) %>%
  rename_with(~ paste0(., "_S2"), starts_with("NDWI")) %>%
  rename_with(~ paste0(., "_S2"), starts_with("EVI")) %>%
  rename_with(~ paste0(., "_S2"), starts_with("SAVI")) %>%
  select(-source)
data_RS_Landsat_ID <- data_RS_Landsat_ID %>%
  rename_with(~ paste0(., "_Landsat"), starts_with("NDVI")) %>%
  rename_with(~ paste0(., "_Landsat"), starts_with("NDMI")) %>%
  rename_with(~ paste0(., "_Landsat"), starts_with("NDWI")) %>%
  rename_with(~ paste0(., "_Landsat"), starts_with("EVI")) %>%
  rename_with(~ paste0(., "_Landsat"), starts_with("SAVI")) %>%
  select(-source)
```

Join S2, S2_phen and Landsat data:

```{r}
data_RS <- data_RS_S2_ID %>% 
  # full_join(data_RS_S2_phen_ID) %>%
  full_join(data_RS_Landsat_ID)
```

Number of observations with NDVI_max data from both S2 and Landsat:

```{r}
nrow(data_RS %>% filter(!is.na(NDVI_max_S2) & !is.na(NDVI_max_Landsat)))
```

Difference between NDVI_max values from S2 and Landsat:

```{r}
data_RS %>% filter(!is.na(NDVI_max_S2) & !is.na(NDVI_max_Landsat)) %>%
  mutate(diff_NDVI_max = abs(NDVI_max_S2 - NDVI_max_Landsat)) %>%
  ggplot(aes(x = diff_NDVI_max, fill = paste(biogeo, unit, sep = "-"))) +
  geom_histogram(color = "black") + 
  facet_wrap(~ paste(biogeo, unit, sep = "-")) + theme(legend.position = "none")
data_RS %>% filter(!is.na(NDMI_max_S2) & !is.na(NDMI_max_Landsat)) %>%
  mutate(diff_NDMI_max = abs(NDMI_max_S2 - NDMI_max_Landsat)) %>%
  ggplot(aes(x = diff_NDMI_max, fill = paste(biogeo, unit, sep = "-"))) +
  geom_histogram(color = "black") + 
  facet_wrap(~ paste(biogeo, unit, sep = "-")) + theme(legend.position = "none")
```

There is a large difference between NDVI values from S2 and Landsat. So far, use the S2 data, but checking with Bea / Jose.

When values are available from both satellites, use S2:

```{r}
data_RS <- data_RS %>%
  mutate(across(
    matches("^(NDVI|NDMI|NDWI|EVI|SAVI)_(max|mean|median|min|mode|p10|p90|stdDev)_S2$"),
    ~ case_when(
      # If both the current column and the corresponding Landsat column are NA,
      # set to NA_real_
      is.na(.x) & is.na(get(sub("_S2$", "_Landsat", cur_column()))) ~ NA_real_,
      # If the corresponding Landsat column is NA, use the current column's value
      is.na(get(sub("_S2$", "_Landsat", cur_column()))) ~ .x,
      # If the current column is NA, use the corresponding Landsat column's value
      is.na(.x) ~ get(sub("_S2$", "_Landsat", cur_column())),
      # Otherwise, use the current column's value
      TRUE ~ .x
      ), .names = "{col}_combined")) %>%
  rename_with(~ sub("_S2_combined$", "", .), matches("_S2_combined$"))
```

Get number of points per biogeo and unit:

```{r}
npoints_bioregion_R <- data_RS %>% count(biogeo, unit) %>%
  mutate(npoints_R = n) %>%
  select(-n)
```

Read number of points per biogeo and unit from GIS:

```{r}
npoints_bioregion_GIS <- read_delim(
  "data/clean/Npoints_bioregion.csv", delim = ";"
  ) %>%
  select (BIOGEO, UNIT, Join_Count) %>%
  mutate(biogeo = BIOGEO, unit = str_remove(UNIT, BIOGEO),
         npoints_GIS = Join_Count) %>%
  mutate(biogeo = ifelse(biogeo == "PAN", "PANONIA", biogeo)) %>%
  mutate(unit = ifelse(biogeo == "PANONIA", NA, unit)) %>%
  select(- BIOGEO, - UNIT, -Join_Count)
```

Merge both and see differences in n points:

```{r}
npoints_bioregion_merged <- full_join(npoints_bioregion_R,
                                      npoints_bioregion_GIS)
```

Nice table to email to Bea:

```{r}
kable(print(npoints_bioregion_merged %>% arrange(biogeo, unit), n = 100))
```



```{r}
db_resurv_RS <- db_resurv %>%
  left_join(data_RS %>% select(-obs_unique_id)) %>%
  left_join(data_RS_CH_ID %>% select(-obs_unique_id)) %>%
  mutate(S2_data = !is.na(NDVI_max_S2) & !is.na(NDMI_max_S2), 
         Landsat_data = !is.na(NDVI_max_Landsat) & !is.na(NDMI_max_Landsat),
         S2_or_Landsat_data = !is.na(NDVI_max) & !is.na(NDMI_max), 
         # S2_phen_data = !is.na(SOS_DOY),
         CH_data = !is.na(canopy_height)) %>%
  # So far, remove cols for _S2 and _Landsat
  select(-matches("_(S2|Landsat)$"))
```

```{r}
db_resurv_RS %>% count(S2_data)
db_resurv_RS %>% count(Landsat_data)
db_resurv_RS %>% count(S2_or_Landsat_data)
db_resurv_RS %>% count(CH_data)
# db_resurv_RS %>% count(S2_phen_data)
```

# Save to clean data

Save clean file for analyses (to be updated continuously due to updates in ReSurvey database and updates on RS data).

```{r}
write_tsv(db_resurv_RS,here("data", "clean","db_resurv_RS_20250610.csv"))
```

# Session info

```{r}
sessionInfo()
```
